{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6092b42-6423-4b4f-81b3-b6ddec64ecf1",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24c94665-4148-40ed-b2a9-516dd3becc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 21:14:45.360979: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-12 21:14:45.857073: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-12 21:14:46.676940: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/dron46/anaconda3/envs/tf/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import transformers\n",
    "import tensorflow as tf\n",
    "import tqdm.notebook as tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32c8114b-e127-446f-acff-4484767da1b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f2bb71b-0083-4f61-85c1-228385e95f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.16.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6998038d-5065-49d1-a9bd-b3acce5bb514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c18c6e-1c88-4e6b-8f13-476b78b88a2b",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e38ac2-a5e2-4435-8c95-0982e3039768",
   "metadata": {},
   "source": [
    "Get the dataset from [here](https://tatoeba.org/en/downloads). Preferably use russian to english translations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e09a5d-8537-4ffa-8583-f09c30028b2d",
   "metadata": {},
   "source": [
    "Use a custom tokenizer that can add bos and eos tokens (pass `add_special_tokens=True` when calling the tokenizer to add them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8312a719-f1cd-4982-a2e8-2178a7abe850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Tokenizer(transformers.GPT2Tokenizer):\n",
    "\n",
    "    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n",
    "        if token_ids_1 is None:\n",
    "            return [self.bos_token_id, *token_ids_0, self.eos_token_id]\n",
    "\n",
    "        return [self.bos_token_id, *token_ids_0, self.bos_token_id, *token_ids_1, self.eos_token_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b187545e-882a-4cd1-8bab-dcec2f33b5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'Tokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dda8f29c-813a-4acb-a710-eba50ae1d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Пары предложений на русский-английский - 2024-10-13.tsv', sep='\\t',  on_bad_lines='skip', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "262cace8-b578-475f-b527-9c77a6bdc5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>243</td>\n",
       "      <td>Один раз в жизни я делаю хорошее дело... И оно...</td>\n",
       "      <td>3257</td>\n",
       "      <td>For once in my life I'm doing a good deed... A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5409</td>\n",
       "      <td>Давайте что-нибудь попробуем!</td>\n",
       "      <td>1276</td>\n",
       "      <td>Let's try something.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5410</td>\n",
       "      <td>Мне пора идти спать.</td>\n",
       "      <td>1277</td>\n",
       "      <td>I have to go to sleep.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5411</td>\n",
       "      <td>Что ты делаешь?</td>\n",
       "      <td>16492</td>\n",
       "      <td>What are you doing?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5411</td>\n",
       "      <td>Что ты делаешь?</td>\n",
       "      <td>511884</td>\n",
       "      <td>What do you make?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733441</th>\n",
       "      <td>5803241</td>\n",
       "      <td>Будь здоров.</td>\n",
       "      <td>2111946</td>\n",
       "      <td>Bless you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733442</th>\n",
       "      <td>12780354</td>\n",
       "      <td>Будь здорова.</td>\n",
       "      <td>2111946</td>\n",
       "      <td>Bless you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733443</th>\n",
       "      <td>12780481</td>\n",
       "      <td>Я хотел бы иметь возможность управлять погодой.</td>\n",
       "      <td>12780477</td>\n",
       "      <td>I wish I could control the weather.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733444</th>\n",
       "      <td>12780663</td>\n",
       "      <td>Нам нужно купить им подарок.</td>\n",
       "      <td>3917718</td>\n",
       "      <td>We need to buy a gift for them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733445</th>\n",
       "      <td>12780664</td>\n",
       "      <td>Том и Мэри что-нибудь помнят?</td>\n",
       "      <td>6519892</td>\n",
       "      <td>Do Tom and Mary remember anything?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>733446 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0                                                  1         2  \\\n",
       "0            243  Один раз в жизни я делаю хорошее дело... И оно...      3257   \n",
       "1           5409                      Давайте что-нибудь попробуем!      1276   \n",
       "2           5410                               Мне пора идти спать.      1277   \n",
       "3           5411                                    Что ты делаешь?     16492   \n",
       "4           5411                                    Что ты делаешь?    511884   \n",
       "...          ...                                                ...       ...   \n",
       "733441   5803241                                       Будь здоров.   2111946   \n",
       "733442  12780354                                      Будь здорова.   2111946   \n",
       "733443  12780481    Я хотел бы иметь возможность управлять погодой.  12780477   \n",
       "733444  12780663                       Нам нужно купить им подарок.   3917718   \n",
       "733445  12780664                      Том и Мэри что-нибудь помнят?   6519892   \n",
       "\n",
       "                                                        3  \n",
       "0       For once in my life I'm doing a good deed... A...  \n",
       "1                                    Let's try something.  \n",
       "2                                  I have to go to sleep.  \n",
       "3                                     What are you doing?  \n",
       "4                                       What do you make?  \n",
       "...                                                   ...  \n",
       "733441                                         Bless you.  \n",
       "733442                                         Bless you.  \n",
       "733443                I wish I could control the weather.  \n",
       "733444                    We need to buy a gift for them.  \n",
       "733445                 Do Tom and Mary remember anything?  \n",
       "\n",
       "[733446 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91b1fe41-3093-4f84-a943-5ef0598dbca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename(columns={0: 'id_ru', 1: 'text_ru', 2: 'id_en', 3: 'text_en'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bb9cbfc-e1b6-4740-a62e-bb26d4117774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_ru</th>\n",
       "      <th>text_ru</th>\n",
       "      <th>id_en</th>\n",
       "      <th>text_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>243</td>\n",
       "      <td>Один раз в жизни я делаю хорошее дело... И оно...</td>\n",
       "      <td>3257</td>\n",
       "      <td>For once in my life I'm doing a good deed... A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5409</td>\n",
       "      <td>Давайте что-нибудь попробуем!</td>\n",
       "      <td>1276</td>\n",
       "      <td>Let's try something.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5410</td>\n",
       "      <td>Мне пора идти спать.</td>\n",
       "      <td>1277</td>\n",
       "      <td>I have to go to sleep.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5411</td>\n",
       "      <td>Что ты делаешь?</td>\n",
       "      <td>16492</td>\n",
       "      <td>What are you doing?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5411</td>\n",
       "      <td>Что ты делаешь?</td>\n",
       "      <td>511884</td>\n",
       "      <td>What do you make?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733441</th>\n",
       "      <td>5803241</td>\n",
       "      <td>Будь здоров.</td>\n",
       "      <td>2111946</td>\n",
       "      <td>Bless you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733442</th>\n",
       "      <td>12780354</td>\n",
       "      <td>Будь здорова.</td>\n",
       "      <td>2111946</td>\n",
       "      <td>Bless you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733443</th>\n",
       "      <td>12780481</td>\n",
       "      <td>Я хотел бы иметь возможность управлять погодой.</td>\n",
       "      <td>12780477</td>\n",
       "      <td>I wish I could control the weather.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733444</th>\n",
       "      <td>12780663</td>\n",
       "      <td>Нам нужно купить им подарок.</td>\n",
       "      <td>3917718</td>\n",
       "      <td>We need to buy a gift for them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733445</th>\n",
       "      <td>12780664</td>\n",
       "      <td>Том и Мэри что-нибудь помнят?</td>\n",
       "      <td>6519892</td>\n",
       "      <td>Do Tom and Mary remember anything?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>733446 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id_ru                                            text_ru     id_en  \\\n",
       "0            243  Один раз в жизни я делаю хорошее дело... И оно...      3257   \n",
       "1           5409                      Давайте что-нибудь попробуем!      1276   \n",
       "2           5410                               Мне пора идти спать.      1277   \n",
       "3           5411                                    Что ты делаешь?     16492   \n",
       "4           5411                                    Что ты делаешь?    511884   \n",
       "...          ...                                                ...       ...   \n",
       "733441   5803241                                       Будь здоров.   2111946   \n",
       "733442  12780354                                      Будь здорова.   2111946   \n",
       "733443  12780481    Я хотел бы иметь возможность управлять погодой.  12780477   \n",
       "733444  12780663                       Нам нужно купить им подарок.   3917718   \n",
       "733445  12780664                      Том и Мэри что-нибудь помнят?   6519892   \n",
       "\n",
       "                                                  text_en  \n",
       "0       For once in my life I'm doing a good deed... A...  \n",
       "1                                    Let's try something.  \n",
       "2                                  I have to go to sleep.  \n",
       "3                                     What are you doing?  \n",
       "4                                       What do you make?  \n",
       "...                                                   ...  \n",
       "733441                                         Bless you.  \n",
       "733442                                         Bless you.  \n",
       "733443                I wish I could control the weather.  \n",
       "733444                    We need to buy a gift for them.  \n",
       "733445                 Do Tom and Mary remember anything?  \n",
       "\n",
       "[733446 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82a0df79-a606-4319-9731-defafcb1e5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_ru      0\n",
       "text_ru    0\n",
       "id_en      0\n",
       "text_en    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60b8ecc2-7789-42e7-b6df-9bab38d79fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "837"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text_ru'].apply(lambda x: len(x)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07c46cc1-775a-4554-a273-0e3a1cee5335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "608846"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text_ru'].apply(lambda x: len(x)).idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "388e6686-e75c-493f-9ec9-131030eb6d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am a Jew. Hath not a Jew eyes? Hath not a Jew hands, organs, dimensions, senses, affections, passions? Fed with the same food, hurt with the same weapons, subject to the same diseases, healed by the same means, warmed and cooled by the same winter and summer, as a Christian is? If you prick us, do we not bleed? If you tickle us, do we not laugh? If you poison us, do we not die? And if you wrong us, shall we not revenge? If we are like you in the rest, we will resemble you in that. If a Jew wrong a Christian, what is his humility? Revenge. If a Christian wrong a Jew, what should his sufferance be by Christian example? Why, revenge. The villainy you teach me, I will execute, and it shall go hard but I will better the instruction.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[608846, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f3b03b7-cf44-4f11-83e9-65267e7c05a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text_ru'].apply(lambda x: len(x)).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b6ec342-1f5e-494f-a9c2-8c00b082d2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dataset['text_ru'].apply(lambda x: len(x)) > 200).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "161e41ce-8f9d-4688-86ad-dec844b46c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset['text_ru'].apply(lambda x: len(x)).hist(figsize=(8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79b98ad-0308-4cb3-b96e-a1a0069be7a9",
   "metadata": {},
   "source": [
    "---\n",
    "Обрезаю очень длинные текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2792baa1-9651-4d92-9171-b7fe78260994",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = dataset[dataset['text_ru'].apply(lambda x: len(x)) <= 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4dffd60-f154-449b-8e9a-df2f36d86a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_ru</th>\n",
       "      <th>text_ru</th>\n",
       "      <th>id_en</th>\n",
       "      <th>text_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>400671</td>\n",
       "      <td>На душе становится тепло, когда ты слышишь в п...</td>\n",
       "      <td>400674</td>\n",
       "      <td>It warms your heart to, when listening to a so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>400671</td>\n",
       "      <td>На душе становится тепло, когда ты слышишь в п...</td>\n",
       "      <td>494506</td>\n",
       "      <td>It warms your heart when, while listening to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>400671</td>\n",
       "      <td>На душе становится тепло, когда ты слышишь в п...</td>\n",
       "      <td>495180</td>\n",
       "      <td>While listening to songs in a what is supposed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>402065</td>\n",
       "      <td>В Китае используется большое количество иерогл...</td>\n",
       "      <td>401970</td>\n",
       "      <td>In China, there is a large number of character...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12169</th>\n",
       "      <td>510907</td>\n",
       "      <td>Дом птицы - лес, дом рыбы - река, дом пчелы - ...</td>\n",
       "      <td>485186</td>\n",
       "      <td>The birds' home is in the forest, the fish's h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667027</th>\n",
       "      <td>11715247</td>\n",
       "      <td>В матче за звание чемпиона мира ФИДЕ 2023 по ш...</td>\n",
       "      <td>11715230</td>\n",
       "      <td>The match for the FIDE 2023 World Chess Champi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706703</th>\n",
       "      <td>12333670</td>\n",
       "      <td>В этом мире нет ничего прекраснее, чем слышать...</td>\n",
       "      <td>12333611</td>\n",
       "      <td>In this world, nothing is more beautiful than ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706732</th>\n",
       "      <td>12334059</td>\n",
       "      <td>Галилео Галилей был итальянским астрономом и в...</td>\n",
       "      <td>4310535</td>\n",
       "      <td>Galileo Galilei was an Italian astronomer and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706737</th>\n",
       "      <td>12334074</td>\n",
       "      <td>Дерзость Цезаря была началом выдающейся военно...</td>\n",
       "      <td>4277919</td>\n",
       "      <td>Caesar’s audacity was the beginning of a very ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712988</th>\n",
       "      <td>12408798</td>\n",
       "      <td>Если вы хотите избавиться от скучного собеседн...</td>\n",
       "      <td>3605474</td>\n",
       "      <td>If you want to get rid of a boring companion a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id_ru                                            text_ru     id_en  \\\n",
       "1633      400671  На душе становится тепло, когда ты слышишь в п...    400674   \n",
       "1634      400671  На душе становится тепло, когда ты слышишь в п...    494506   \n",
       "1635      400671  На душе становится тепло, когда ты слышишь в п...    495180   \n",
       "1686      402065  В Китае используется большое количество иерогл...    401970   \n",
       "12169     510907  Дом птицы - лес, дом рыбы - река, дом пчелы - ...    485186   \n",
       "...          ...                                                ...       ...   \n",
       "667027  11715247  В матче за звание чемпиона мира ФИДЕ 2023 по ш...  11715230   \n",
       "706703  12333670  В этом мире нет ничего прекраснее, чем слышать...  12333611   \n",
       "706732  12334059  Галилео Галилей был итальянским астрономом и в...   4310535   \n",
       "706737  12334074  Дерзость Цезаря была началом выдающейся военно...   4277919   \n",
       "712988  12408798  Если вы хотите избавиться от скучного собеседн...   3605474   \n",
       "\n",
       "                                                  text_en  \n",
       "1633    It warms your heart to, when listening to a so...  \n",
       "1634    It warms your heart when, while listening to a...  \n",
       "1635    While listening to songs in a what is supposed...  \n",
       "1686    In China, there is a large number of character...  \n",
       "12169   The birds' home is in the forest, the fish's h...  \n",
       "...                                                   ...  \n",
       "667027  The match for the FIDE 2023 World Chess Champi...  \n",
       "706703  In this world, nothing is more beautiful than ...  \n",
       "706732  Galileo Galilei was an Italian astronomer and ...  \n",
       "706737  Caesar’s audacity was the beginning of a very ...  \n",
       "712988  If you want to get rid of a boring companion a...  \n",
       "\n",
       "[72 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2[dataset2['text_en'].apply(lambda x: len(x)) > 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48dba7e8-0d5f-474a-afd3-0ceee6aee728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('На душе становится тепло, когда ты слышишь в песне на (казалось бы!) чужом языке: словацком, македонском, словенском, — знакомые с детства слова и даже понимаешь целые фразы.',\n",
       " 'It warms your heart to, when listening to a song in a (seemingly!) foreign language like Slovak, Macedonian, Slovenian, hear words you have known since your childhood and even understand whole phrases.')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2.loc[1633, 'text_ru'], dataset2.loc[1633, 'text_en'],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9a5a127b-8f30-448d-9015-2c6a45234b56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = tokenizer(list(dataset2['text_ru']), add_special_tokens=False)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f6e986c0-337b-41b1-97ee-06c088dc4c6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(list(map(len, a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3d9204e1-b50c-4457-b861-137518b64114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGdCAYAAAD+JxxnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAjgUlEQVR4nO3df0xV9/3H8RegF/x1L/UHXJlY6eyqTMWJinf9tpmTeXW0qVMT7UxLra3RoanS+mtz2DZNcDZb1flrS5Piklp//KGdUnEMK6b11h8oqdpq2sUOO7xga+EqFVDu+f6xcOYVK2DFq3yej+Qm5ZzPPbzvPROeu95zjbAsyxIAAICBIsM9AAAAQLgQQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACM1SHcA9zNgsGgysvL1a1bN0VERIR7HAAA0AKWZenixYtKSEhQZOTNX/MhhG6ivLxciYmJ4R4DAADcgrNnz6pPnz43XUMI3US3bt0k/feJdDqdYZ4GAAC0RCAQUGJiov17/GYIoZto/Oswp9NJCAEAcI9pydtaeLM0AAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACM1SHcA+De0m9xfrhHaLUvlmeEewQAwF2KV4QAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgrO8VQsuXL1dERITmzZtnb6utrVVWVpZ69Oihrl27atKkSaqoqAi5X1lZmTIyMtS5c2fFxcVpwYIFunr1asiaffv2adiwYYqOjlb//v2Vl5fX5PuvXbtW/fr1U0xMjNLS0nTo0KGQ/S2ZBQAAmOuWQ+jw4cP6y1/+oiFDhoRsnz9/vnbu3Klt27apuLhY5eXlmjhxor2/oaFBGRkZqq+v14EDB7Rx40bl5eUpJyfHXnPmzBllZGRo9OjRKi0t1bx58/Tcc89pz5499potW7YoOztby5Yt09GjR5WSkiKv16vKysoWzwIAAMwWYVmW1do7Xbp0ScOGDdO6dev02muvaejQoVq5cqWqq6vVq1cvbdq0SZMnT5YknTp1SgMHDpTP59OoUaO0e/duPfbYYyovL1d8fLwkacOGDVq0aJHOnz8vh8OhRYsWKT8/XydOnLC/59SpU1VVVaWCggJJUlpamkaMGKE1a9ZIkoLBoBITEzV37lwtXry4RbM0JxAIyOVyqbq6Wk6ns7VPU7vUb3F+uEdotS+WZ4R7BADAHdSa39+39IpQVlaWMjIylJ6eHrK9pKREV65cCdk+YMAA9e3bVz6fT5Lk8/k0ePBgO4Ikyev1KhAI6OTJk/aa64/t9XrtY9TX16ukpCRkTWRkpNLT0+01LZnlenV1dQoEAiE3AADQfnVo7R02b96so0eP6vDhw032+f1+ORwOxcbGhmyPj4+X3++311wbQY37G/fdbE0gENDly5f1zTffqKGh4YZrTp061eJZrpebm6tXXnnlJo8eAAC0J616Rejs2bN64YUX9PbbbysmJqatZgqbJUuWqLq62r6dPXs23CMBAIA21KoQKikpUWVlpYYNG6YOHTqoQ4cOKi4u1urVq9WhQwfFx8ervr5eVVVVIferqKiQ2+2WJLnd7iZXbjV+3dwap9OpTp06qWfPnoqKirrhmmuP0dws14uOjpbT6Qy5AQCA9qtVITRmzBgdP35cpaWl9m348OGaNm2a/d8dO3ZUUVGRfZ/Tp0+rrKxMHo9HkuTxeHT8+PGQq7sKCwvldDqVnJxsr7n2GI1rGo/hcDiUmpoasiYYDKqoqMhek5qa2uwsAADAbK16j1C3bt00aNCgkG1dunRRjx497O0zZsxQdna2unfvLqfTqblz58rj8dhXaY0dO1bJycl66qmntGLFCvn9fi1dulRZWVmKjo6WJM2aNUtr1qzRwoUL9eyzz2rv3r3aunWr8vP/d8VSdna2MjMzNXz4cI0cOVIrV65UTU2Npk+fLklyuVzNzgIAAMzW6jdLN+eNN95QZGSkJk2apLq6Onm9Xq1bt87eHxUVpV27dmn27NnyeDzq0qWLMjMz9eqrr9prkpKSlJ+fr/nz52vVqlXq06eP3nzzTXm9XnvNlClTdP78eeXk5Mjv92vo0KEqKCgIeQN1c7MAAACz3dLnCJmCzxFqis8RAgDc7dr8c4QAAADaA0IIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGKtVIbR+/XoNGTJETqdTTqdTHo9Hu3fvtvfX1tYqKytLPXr0UNeuXTVp0iRVVFSEHKOsrEwZGRnq3Lmz4uLitGDBAl29ejVkzb59+zRs2DBFR0erf//+ysvLazLL2rVr1a9fP8XExCgtLU2HDh0K2d+SWQAAgNlaFUJ9+vTR8uXLVVJSoiNHjujnP/+5nnjiCZ08eVKSNH/+fO3cuVPbtm1TcXGxysvLNXHiRPv+DQ0NysjIUH19vQ4cOKCNGzcqLy9POTk59pozZ84oIyNDo0ePVmlpqebNm6fnnntOe/bssdds2bJF2dnZWrZsmY4ePaqUlBR5vV5VVlbaa5qbBQAAIMKyLOv7HKB79+56/fXXNXnyZPXq1UubNm3S5MmTJUmnTp3SwIED5fP5NGrUKO3evVuPPfaYysvLFR8fL0nasGGDFi1apPPnz8vhcGjRokXKz8/XiRMn7O8xdepUVVVVqaCgQJKUlpamESNGaM2aNZKkYDCoxMREzZ07V4sXL1Z1dXWzs7REIBCQy+VSdXW1nE7n93ma2o1+i/PDPUKrfbE8I9wjAADuoNb8/r7l9wg1NDRo8+bNqqmpkcfjUUlJia5cuaL09HR7zYABA9S3b1/5fD5Jks/n0+DBg+0IkiSv16tAIGC/quTz+UKO0bim8Rj19fUqKSkJWRMZGan09HR7TUtmAQAA6NDaOxw/flwej0e1tbXq2rWrtm/fruTkZJWWlsrhcCg2NjZkfXx8vPx+vyTJ7/eHRFDj/sZ9N1sTCAR0+fJlffPNN2poaLjhmlOnTtnHaG6WG6mrq1NdXZ39dSAQaObZAAAA97JWvyL00EMPqbS0VAcPHtTs2bOVmZmpTz75pC1mu+Nyc3PlcrnsW2JiYrhHAgAAbajVIeRwONS/f3+lpqYqNzdXKSkpWrVqldxut+rr61VVVRWyvqKiQm63W5LkdrubXLnV+HVza5xOpzp16qSePXsqKirqhmuuPUZzs9zIkiVLVF1dbd/Onj3bsicFAADck7735wgFg0HV1dUpNTVVHTt2VFFRkb3v9OnTKisrk8fjkSR5PB4dP3485OquwsJCOZ1OJScn22uuPUbjmsZjOBwOpaamhqwJBoMqKiqy17RklhuJjo62Pxqg8QYAANqvVr1HaMmSJRo/frz69u2rixcvatOmTdq3b5/27Nkjl8ulGTNmKDs7W927d5fT6dTcuXPl8Xjsq7TGjh2r5ORkPfXUU1qxYoX8fr+WLl2qrKwsRUdHS5JmzZqlNWvWaOHChXr22We1d+9ebd26Vfn5/7taKTs7W5mZmRo+fLhGjhyplStXqqamRtOnT5ekFs0CAADQqhCqrKzU008/rXPnzsnlcmnIkCHas2ePfvGLX0iS3njjDUVGRmrSpEmqq6uT1+vVunXr7PtHRUVp165dmj17tjwej7p06aLMzEy9+uqr9pqkpCTl5+dr/vz5WrVqlfr06aM333xTXq/XXjNlyhSdP39eOTk58vv9Gjp0qAoKCkLeQN3cLAAAAN/7c4TaMz5HqCk+RwgAcLe7I58jBAAAcK8jhAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsTqEewCT9VucH+4RAAAwGq8IAQAAYxFCAADAWIQQAAAwFiEEAACM1aoQys3N1YgRI9StWzfFxcVpwoQJOn36dMia2tpaZWVlqUePHuratasmTZqkioqKkDVlZWXKyMhQ586dFRcXpwULFujq1asha/bt26dhw4YpOjpa/fv3V15eXpN51q5dq379+ikmJkZpaWk6dOhQq2cBAADmalUIFRcXKysrSx999JEKCwt15coVjR07VjU1Nfaa+fPna+fOndq2bZuKi4tVXl6uiRMn2vsbGhqUkZGh+vp6HThwQBs3blReXp5ycnLsNWfOnFFGRoZGjx6t0tJSzZs3T88995z27Nljr9myZYuys7O1bNkyHT16VCkpKfJ6vaqsrGzxLAAAwGwRlmVZt3rn8+fPKy4uTsXFxXr00UdVXV2tXr16adOmTZo8ebIk6dSpUxo4cKB8Pp9GjRql3bt367HHHlN5ebni4+MlSRs2bNCiRYt0/vx5ORwOLVq0SPn5+Tpx4oT9vaZOnaqqqioVFBRIktLS0jRixAitWbNGkhQMBpWYmKi5c+dq8eLFLZqlOYFAQC6XS9XV1XI6nbf6NH0nLp+/M75YnhHuEQAAd1Brfn9/r/cIVVdXS5K6d+8uSSopKdGVK1eUnp5urxkwYID69u0rn88nSfL5fBo8eLAdQZLk9XoVCAR08uRJe821x2hc03iM+vp6lZSUhKyJjIxUenq6vaYls1yvrq5OgUAg5AYAANqvWw6hYDCoefPm6eGHH9agQYMkSX6/Xw6HQ7GxsSFr4+Pj5ff77TXXRlDj/sZ9N1sTCAR0+fJlffXVV2poaLjhmmuP0dws18vNzZXL5bJviYmJLXw2AADAveiWQygrK0snTpzQ5s2bb+c8YbVkyRJVV1fbt7Nnz4Z7JAAA0IZu6Z/YmDNnjnbt2qX9+/erT58+9na32636+npVVVWFvBJTUVEht9ttr7n+6q7GK7muXXP91V0VFRVyOp3q1KmToqKiFBUVdcM11x6juVmuFx0drejo6FY8EwAA4F7WqleELMvSnDlztH37du3du1dJSUkh+1NTU9WxY0cVFRXZ206fPq2ysjJ5PB5Jksfj0fHjx0Ou7iosLJTT6VRycrK95tpjNK5pPIbD4VBqamrImmAwqKKiIntNS2YBAABma9UrQllZWdq0aZPeffdddevWzX6vjcvlUqdOneRyuTRjxgxlZ2ere/fucjqdmjt3rjwej32V1tixY5WcnKynnnpKK1askN/v19KlS5WVlWW/GjNr1iytWbNGCxcu1LPPPqu9e/dq69atys//31VW2dnZyszM1PDhwzVy5EitXLlSNTU1mj59uj1Tc7MAAACztSqE1q9fL0n62c9+FrL9rbfe0jPPPCNJeuONNxQZGalJkyaprq5OXq9X69ats9dGRUVp165dmj17tjwej7p06aLMzEy9+uqr9pqkpCTl5+dr/vz5WrVqlfr06aM333xTXq/XXjNlyhSdP39eOTk58vv9Gjp0qAoKCkLeQN3cLAAAwGzf63OE2js+R6h94HOEAMAsd+xzhAAAAO5lhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwVqtDaP/+/Xr88ceVkJCgiIgI7dixI2S/ZVnKyclR79691alTJ6Wnp+uzzz4LWXPhwgVNmzZNTqdTsbGxmjFjhi5duhSy5uOPP9YjjzyimJgYJSYmasWKFU1m2bZtmwYMGKCYmBgNHjxY7733XqtnAQAA5mp1CNXU1CglJUVr16694f4VK1Zo9erV2rBhgw4ePKguXbrI6/WqtrbWXjNt2jSdPHlShYWF2rVrl/bv36+ZM2fa+wOBgMaOHav7779fJSUlev311/Xyyy/rr3/9q73mwIEDevLJJzVjxgwdO3ZMEyZM0IQJE3TixIlWzQIAAMwVYVmWdct3jojQ9u3bNWHCBEn/fQUmISFBL774ol566SVJUnV1teLj45WXl6epU6fq008/VXJysg4fPqzhw4dLkgoKCvTLX/5SX375pRISErR+/Xr97ne/k9/vl8PhkCQtXrxYO3bs0KlTpyRJU6ZMUU1NjXbt2mXPM2rUKA0dOlQbNmxo0SzNCQQCcrlcqq6ultPpvNWn6Tv1W5x/24+Jpr5YnhHuEQAAd1Brfn/f1vcInTlzRn6/X+np6fY2l8ultLQ0+Xw+SZLP51NsbKwdQZKUnp6uyMhIHTx40F7z6KOP2hEkSV6vV6dPn9Y333xjr7n2+zSuafw+LZnlenV1dQoEAiE3AADQft3WEPL7/ZKk+Pj4kO3x8fH2Pr/fr7i4uJD9HTp0UPfu3UPW3OgY136P71pz7f7mZrlebm6uXC6XfUtMTGzBowYAAPcqrhq7xpIlS1RdXW3fzp49G+6RAABAG7qtIeR2uyVJFRUVIdsrKirsfW63W5WVlSH7r169qgsXLoSsudExrv0e37Xm2v3NzXK96OhoOZ3OkBsAAGi/bmsIJSUlye12q6ioyN4WCAR08OBBeTweSZLH41FVVZVKSkrsNXv37lUwGFRaWpq9Zv/+/bpy5Yq9prCwUA899JDuu+8+e82136dxTeP3acksAADAbK0OoUuXLqm0tFSlpaWS/vum5NLSUpWVlSkiIkLz5s3Ta6+9pr///e86fvy4nn76aSUkJNhXlg0cOFDjxo3T888/r0OHDunDDz/UnDlzNHXqVCUkJEiSfv3rX8vhcGjGjBk6efKktmzZolWrVik7O9ue44UXXlBBQYH++Mc/6tSpU3r55Zd15MgRzZkzR5JaNAsAADBbh9be4ciRIxo9erT9dWOcZGZmKi8vTwsXLlRNTY1mzpypqqoq/d///Z8KCgoUExNj3+ftt9/WnDlzNGbMGEVGRmrSpElavXq1vd/lcukf//iHsrKylJqaqp49eyonJyfks4Z++tOfatOmTVq6dKl++9vf6sEHH9SOHTs0aNAge01LZgEAAOb6Xp8j1N7xOULtA58jBABmCdvnCAEAANxLCCEAAGAsQggAABiLEAIAAMYihAAAgLEIIQAAYCxCCAAAGIsQAgAAxiKEAACAsQghAABgLEIIAAAYixACAADGIoQAAICxCCEAAGAsQggAABirQ7gHANpav8X54R6h1b5YnhHuEQDACLwiBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAYxFCAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAY3UI9wAAmuq3OD/cI7TaF8szwj0CALQarwgBAABjEUIAAMBYhBAAADCWESG0du1a9evXTzExMUpLS9OhQ4fCPRIAALgLtPsQ2rJli7Kzs7Vs2TIdPXpUKSkp8nq9qqysDPdoAAAgzCIsy7LCPURbSktL04gRI7RmzRpJUjAYVGJioubOnavFixff9L6BQEAul0vV1dVyOp23fbZ78cogoD3hSjegfWrN7+92ffl8fX29SkpKtGTJEntbZGSk0tPT5fP5mqyvq6tTXV2d/XV1dbWk/z6hbSFY922bHBdAy/Sdvy3cI7TaiVe84R4BuOs1/t5uyWs97TqEvvrqKzU0NCg+Pj5ke3x8vE6dOtVkfW5url555ZUm2xMTE9tsRgBoDdfKcE8A3DsuXrwol8t10zXtOoRaa8mSJcrOzra/DgaDunDhgnr06KGIiIhbOmYgEFBiYqLOnj3bJn+9hpbjXNxdOB93D87F3YNzcXtYlqWLFy8qISGh2bXtOoR69uypqKgoVVRUhGyvqKiQ2+1usj46OlrR0dEh22JjY2/LLE6nk/9R3yU4F3cXzsfdg3Nx9+BcfH/NvRLUqF1fNeZwOJSamqqioiJ7WzAYVFFRkTweTxgnAwAAd4N2/YqQJGVnZyszM1PDhw/XyJEjtXLlStXU1Gj69OnhHg0AAIRZuw+hKVOm6Pz588rJyZHf79fQoUNVUFDQ5A3UbSU6OlrLli1r8lduuPM4F3cXzsfdg3Nx9+Bc3Hnt/nOEAAAAvku7fo8QAADAzRBCAADAWIQQAAAwFiEEAACMRQi1obVr16pfv36KiYlRWlqaDh06FO6RjPDyyy8rIiIi5DZgwAB7f21trbKystSjRw917dpVkyZNavKhm7g1+/fv1+OPP66EhARFRERox44dIfsty1JOTo569+6tTp06KT09XZ999lnImgsXLmjatGlyOp2KjY3VjBkzdOnSpTv4KNqH5s7FM8880+TPybhx40LWcC5uj9zcXI0YMULdunVTXFycJkyYoNOnT4esacnPpbKyMmVkZKhz586Ki4vTggULdPXq1Tv5UNolQqiNbNmyRdnZ2Vq2bJmOHj2qlJQUeb1eVVZWhns0I/z4xz/WuXPn7NsHH3xg75s/f7527typbdu2qbi4WOXl5Zo4cWIYp20/ampqlJKSorVr195w/4oVK7R69Wpt2LBBBw8eVJcuXeT1elVbW2uvmTZtmk6ePKnCwkLt2rVL+/fv18yZM+/UQ2g3mjsXkjRu3LiQPyfvvPNOyH7Oxe1RXFysrKwsffTRRyosLNSVK1c0duxY1dTU2Gua+7nU0NCgjIwM1dfX68CBA9q4caPy8vKUk5MTjofUvlhoEyNHjrSysrLsrxsaGqyEhAQrNzc3jFOZYdmyZVZKSsoN91VVVVkdO3a0tm3bZm/79NNPLUmWz+e7QxOaQZK1fft2++tgMGi53W7r9ddft7dVVVVZ0dHR1jvvvGNZlmV98sknliTr8OHD9prdu3dbERER1n/+8587Nnt7c/25sCzLyszMtJ544onvvA/nou1UVlZakqzi4mLLslr2c+m9996zIiMjLb/fb69Zv3695XQ6rbq6ujv7ANoZXhFqA/X19SopKVF6erq9LTIyUunp6fL5fGGczByfffaZEhIS9MADD2jatGkqKyuTJJWUlOjKlSsh52bAgAHq27cv56aNnTlzRn6/P+S5d7lcSktLs597n8+n2NhYDR8+3F6Tnp6uyMhIHTx48I7P3N7t27dPcXFxeuihhzR79mx9/fXX9j7ORduprq6WJHXv3l1Sy34u+Xw+DR48OOTDgL1erwKBgE6ePHkHp29/CKE28NVXX6mhoaHJp1fHx8fL7/eHaSpzpKWlKS8vTwUFBVq/fr3OnDmjRx55RBcvXpTf75fD4Wjyj+lybtpe4/N7sz8Xfr9fcXFxIfs7dOig7t27c35us3Hjxulvf/ubioqK9Ic//EHFxcUaP368GhoaJHEu2kowGNS8efP08MMPa9CgQZLUop9Lfr//hn92Gvfh1rX7f2ID5hk/frz930OGDFFaWpruv/9+bd26VZ06dQrjZMDdY+rUqfZ/Dx48WEOGDNEPf/hD7du3T2PGjAnjZO1bVlaWTpw4EfK+RYQXrwi1gZ49eyoqKqrJO/4rKirkdrvDNJW5YmNj9aMf/Uiff/653G636uvrVVVVFbKGc9P2Gp/fm/25cLvdTS4ouHr1qi5cuMD5aWMPPPCAevbsqc8//1wS56ItzJkzR7t27dL777+vPn362Ntb8nPJ7Xbf8M9O4z7cOkKoDTgcDqWmpqqoqMjeFgwGVVRUJI/HE8bJzHTp0iX961//Uu/evZWamqqOHTuGnJvTp0+rrKyMc9PGkpKS5Ha7Q577QCCggwcP2s+9x+NRVVWVSkpK7DV79+5VMBhUWlraHZ/ZJF9++aW+/vpr9e7dWxLn4nayLEtz5szR9u3btXfvXiUlJYXsb8nPJY/Ho+PHj4fEaWFhoZxOp5KTk+/MA2mvwv1u7fZq8+bNVnR0tJWXl2d98skn1syZM63Y2NiQd/yjbbz44ovWvn37rDNnzlgffvihlZ6ebvXs2dOqrKy0LMuyZs2aZfXt29fau3evdeTIEcvj8VgejyfMU7cPFy9etI4dO2YdO3bMkmT96U9/so4dO2b9+9//tizLspYvX27FxsZa7777rvXxxx9bTzzxhJWUlGRdvnzZPsa4ceOsn/zkJ9bBgwetDz74wHrwwQetJ598MlwP6Z51s3Nx8eJF66WXXrJ8Pp915swZ65///Kc1bNgw68EHH7Rqa2vtY3Aubo/Zs2dbLpfL2rdvn3Xu3Dn79u2339prmvu5dPXqVWvQoEHW2LFjrdLSUqugoMDq1auXtWTJknA8pHaFEGpDf/7zn62+fftaDofDGjlypPXRRx+FeyQjTJkyxerdu7flcDisH/zgB9aUKVOszz//3N5/+fJl6ze/+Y113333WZ07d7Z+9atfWefOnQvjxO3H+++/b0lqcsvMzLQs67+X0P/+97+34uPjrejoaGvMmDHW6dOnQ47x9ddfW08++aTVtWtXy+l0WtOnT7cuXrwYhkdzb7vZufj222+tsWPHWr169bI6duxo3X///dbzzz/f5P+ocS5ujxudB0nWW2+9Za9pyc+lL774who/frzVqVMnq2fPntaLL75oXbly5Q4/mvYnwrIs606/CgUAAHA34D1CAADAWIQQAAAwFiEEAACMRQgBAABjEUIAAMBYhBAAADAWIQQAAIxFCAEAAGMRQgAAwFiEEAAAMBYhBAAAjEUIAQAAY/0/KcfGz/K8pOYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(list(map(len, a)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dbdbd320-ce4c-4bc8-857c-968eeafd8f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2['text_en'].apply(lambda x: len(x)).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0daf10cd-040e-4a9b-855a-51ef379ce40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dataset2['text_en'].apply(lambda x: len(x)) > 200).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "67b2dcd2-20fa-4918-9d7c-7c40ca34035e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset2['text_en'].apply(lambda x: len(x)).hist(figsize=(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "98e24771-396f-4eab-aed2-1109897bf0f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b = tokenizer(list(dataset2['text_en']), add_special_tokens=True)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "126bc107-d8fc-4702-a939-229407d360b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(list(map(len, b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7dd7f67f-8642-455c-ac97-484bb47edc71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(list(map(len, b)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f4f399-308a-457b-a3ce-a8ede414603e",
   "metadata": {},
   "source": [
    "Since the dataset is rather large, you can omit the validation dataset and just use a set of test sentences after the training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff78613-15ce-4695-aced-4379ec067765",
   "metadata": {},
   "source": [
    "Create a dataset that returns the following\n",
    "* A pair of tensors `((None, L), (None, P))` -- input sequence of tokens and output sequence of tokens to be fed into decoder (this should start with the BOS token)\n",
    "* A tensor `(None, P)` -- output sequence of tokens to be predicted (this should end with EOS token)\n",
    "* A tensor `(None, P)` -- a masking tensor marking padded tokens with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "638dd066-e806-4823-8135-e8d15e58be9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ru = tokenizer(list(dataset2['text_ru']), truncation=True, padding='max_length', max_length=32, return_tensors='np', add_special_tokens=False)['input_ids'].astype(np.int32)\n",
    "token_en = tokenizer(list(dataset2['text_en']), truncation=True, padding='max_length', max_length=16, return_tensors='np', add_special_tokens=True)['input_ids'].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "443d0968-284c-4046-89bf-77515b42de0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_split(\n",
    "    tokens_ru: np.ndarray[np.ndarray[int]],\n",
    "    tokens_en: np.ndarray[np.ndarray[int]],\n",
    "    shuffle: bool = True,\n",
    "    seed: int | None = 747,\n",
    "    subset: str | None = None,\n",
    "    test_split: float | None = None,\n",
    "    batch_size: int = 64\n",
    "):\n",
    "\n",
    "    if (subset is not None) != (test_split is not None):\n",
    "        raise ValueError(\"If 'subset' is set, 'test_split' must be set, and inversely.\")\n",
    "\n",
    "    if subset not in {\"train\", \"test\", None}:\n",
    "        raise ValueError(\n",
    "            '`subset` must be either \"train\", \"test\" 'f\"received: {subset}\"\n",
    "        )\n",
    "\n",
    "    if shuffle:\n",
    "        rng = np.random.default_rng(seed)\n",
    "        idx = rng.choice(len(tokens_ru), size=len(tokens_ru), replace=False)\n",
    "        tokens_ru = tokens_ru[idx]\n",
    "        tokens_en = tokens_en[idx]\n",
    "\n",
    "    if test_split is not None:  \n",
    "        num_samples = int((1 - test_split) * len(tokens_ru))\n",
    "        \n",
    "        if subset == 'train':\n",
    "            tokens_ru, tokens_en = tokens_ru[:num_samples], tokens_en[:num_samples]\n",
    "        elif subset == 'test':\n",
    "            tokens_ru, tokens_en = tokens_ru[num_samples:], tokens_en[num_samples:]\n",
    "\n",
    "    tokens_ru_dataset = tf.data.Dataset.from_tensor_slices(tokens_ru)\n",
    "    tokens_en_dataset = tf.data.Dataset.from_tensor_slices(tokens_en)\n",
    "    \n",
    "    output_tokens_en = tokens_en_dataset.map(lambda x: x[1:])\n",
    "    input_tokens_en = tokens_en_dataset.map(lambda x: x[:-1])\n",
    "    \n",
    "    tokens_en_range = tf.range(input_tokens_en.element_spec.shape[0])\n",
    "    mask_tokens_en = output_tokens_en.map(\n",
    "        lambda x: tf.cast(\n",
    "            tokens_en_range <= tf.math.reduce_sum(\n",
    "                tf.cast(\n",
    "                    x != tokenizer.pad_token_id,\n",
    "                    tf.int32\n",
    "                )\n",
    "            ),\n",
    "            tf.float32\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    dataset = tf.data.Dataset.zip((\n",
    "        tf.data.Dataset.zip((tokens_ru_dataset, input_tokens_en)),\n",
    "        output_tokens_en,\n",
    "        mask_tokens_en\n",
    "    )).batch(batch_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8778d77-7902-4be9-8966-4e50aac15590",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 21:17:38.251856: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-12 21:17:38.252010: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-12 21:17:38.252040: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-12 21:17:38.252540: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-12 21:17:38.252569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-11-12 21:17:38.252625: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-12 21:17:38.252642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "train_dataset = get_dataset_split(token_ru, token_en, shuffle=True, seed=747, subset='train', test_split=0.3, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f3e50c8-51ed-44f9-917b-28c2f33bffa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=((TensorSpec(shape=(None, 32), dtype=tf.int32, name=None), TensorSpec(shape=(None, 15), dtype=tf.int32, name=None)), TensorSpec(shape=(None, 15), dtype=tf.int32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19963b19-636c-4d93-8608-d586b530b0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, out, msk = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef33912c-8b51-476e-89f4-fa841ffa2328",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(256, 32), dtype=int32, numpy=\n",
       " array([[  140,   252, 22177, ..., 50256, 50256, 50256],\n",
       "        [  140,   253, 21169, ...,   220, 21727, 20375],\n",
       "        [  140,    94, 43666, ..., 50256, 50256, 50256],\n",
       "        ...,\n",
       "        [  140,   253, 15166, ..., 50256, 50256, 50256],\n",
       "        [  140,   251, 16843, ..., 16142, 20375, 16843],\n",
       "        [  140,    95, 45035, ..., 50256, 50256, 50256]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(256, 15), dtype=int32, numpy=\n",
       " array([[50256,  1544, 21893, ..., 50256, 50256, 50256],\n",
       "        [50256,  5703,  2666, ..., 50256, 50256, 50256],\n",
       "        [50256,  1858,   338, ..., 50256, 50256, 50256],\n",
       "        ...,\n",
       "        [50256,  2504,   338, ..., 50256, 50256, 50256],\n",
       "        [50256,  4366,  1402, ..., 50256, 50256, 50256],\n",
       "        [50256, 11633,    77, ..., 50256, 50256, 50256]], dtype=int32)>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98241b19-d6c3-4b53-a409-67dd570a57c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(256, 15), dtype=int32, numpy=\n",
       " array([[ 1544, 21893,   757, ..., 50256, 50256, 50256],\n",
       "        [ 5703,  2666,   340, ..., 50256, 50256, 50256],\n",
       "        [ 1858,   338,   645, ..., 50256, 50256, 50256],\n",
       "        ...,\n",
       "        [ 2504,   338,  1521, ..., 50256, 50256, 50256],\n",
       "        [ 4366,  1402, 17038, ..., 50256, 50256, 50256],\n",
       "        [11633,    77,   470, ..., 50256, 50256, 50256]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(256, 15), dtype=float32, numpy=\n",
       " array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "        [1., 1., 1., ..., 0., 0., 0.],\n",
       "        [1., 1., 1., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 0., 0.],\n",
       "        [1., 1., 1., ..., 0., 0., 0.],\n",
       "        [1., 1., 1., ..., 0., 0., 0.]], dtype=float32)>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out, msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac98d6cb-bcc5-4fdd-81c1-0a95df64a17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(15,), dtype=int32, numpy=\n",
       "array([ 1544, 21893,   757,    13, 50256,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0], dtype=int32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0] * tf.cast(msk[0], tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d08d83d8-3f8c-4b9a-a650-89aeee8c42a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = get_dataset_split(token_ru, token_en, shuffle=True, seed=747, subset='test', test_split=0.3, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff24dcac-c9f8-4d56-b584-5208c423f196",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c219a81a-59ea-4b56-96da-caa0e24c3db5",
   "metadata": {},
   "source": [
    "Create a model for training. The model should have two inputs: input sequence `(None, L)` and output sequence`(None, P)`. The model output is a single tensor `(None, P)` logits (or probabilities) of the next token predicted for each input one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4385d383-0d18-4f4d-bb32-82256189a8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(prefix: str | None = None, suffix: str | None = None, separator: str = '_') -> str | None:\n",
    "    return prefix and prefix + separator + suffix or suffix or None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaf444d-10f3-497d-8cc5-22a86835f433",
   "metadata": {},
   "source": [
    "Try to add attention to your model (for example [additive attention](https://keras.io/api/layers/attention_layers/additive_attention/)), does it perform better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "37bfe4c6-32b9-4c2e-95f1-b28af0f329a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(\n",
    "    units: int,\n",
    "    n_tokens: int,\n",
    "    n_labels: int,\n",
    "    n_stacks: int = 1,\n",
    "    bidirectional: bool = False,\n",
    "    name: str | None = None,\n",
    "    cell_type: type[tf.keras.layers.Layer] = tf.keras.layers.LSTMCell,\n",
    "    attention_flg = False\n",
    ") -> tf.keras.Model:\n",
    "    '''Creates a model with RNN architecture for sequence to sequence classification.\n",
    "\n",
    "    Arguments:\n",
    "        units: dimensionality of RNN cells\n",
    "        n_tokens: number of tokens in the tokenizer dictionary\n",
    "        n_labels: number of labels to be predicted\n",
    "        n_stacks: number of RNN cells in the stack (1 -- no stacking)\n",
    "        bidirectional: whether or not the model is bidirectional\n",
    "        name: the model name\n",
    "        cell_type: type of a cell to use, either keras.layers.LSTMCell or keras.layers.GRUCell\n",
    "\n",
    "    Returns:\n",
    "        The model'''\n",
    "\n",
    "    inputs_encoder = tf.keras.layers.Input((None, ), dtype=tf.int32, name=get_name(name, 'input_encoder'))\n",
    "    embedding = tf.keras.layers.Embedding(n_tokens, units, name=get_name(name, 'embedding_encoder'))(inputs_encoder)\n",
    "    \n",
    "    if bidirectional:\n",
    "        rnn_layer, *s = tf.keras.layers.Bidirectional(\n",
    "            tf.keras.layers.RNN(\n",
    "                [cell_type(units) for _ in range(n_stacks)],\n",
    "                return_sequences=True,\n",
    "                return_state=True,\n",
    "                name=get_name(name, 'rnn_encoder')\n",
    "            ), name=get_name(name, 'bidirectional')\n",
    "        )(embedding)\n",
    "\n",
    "        if cell_type == tf.keras.layers.LSTMCell:\n",
    "                forward_states = s[:n_stacks]\n",
    "                backward_states = s[n_stacks:]\n",
    "                \n",
    "                initial_state = [\n",
    "                    [\n",
    "                        tf.keras.layers.Concatenate(axis=-1)([forward[0], backward[0]]),\n",
    "                        tf.keras.layers.Concatenate(axis=-1)([forward[1], backward[1]])\n",
    "                    ]\n",
    "                    for forward, backward in zip(forward_states, backward_states)\n",
    "                ]\n",
    "        else:\n",
    "            forward_states = s[:n_stacks]\n",
    "            backward_states = s[n_stacks:]\n",
    "                \n",
    "            initial_state = [tf.keras.layers.Concatenate(axis=-1)([forward, backward]) for forward, backward in zip(forward_states, backward_states)]\n",
    "\n",
    "        # if cell_type == tf.keras.layers.LSTMCell:\n",
    "        #     s = [el for elem in s for el in (elem if isinstance(elem, list) else [elem])]\n",
    "        #     forward_end = s[len(s)//2 - 2: len(s)//2]\n",
    "        #     backword_end = s[len(s) - 2:]\n",
    "\n",
    "        #     initial_state = [tf.keras.layers.Concatenate(axis=-1)([forward_end[0], backword_end[0]]),\n",
    "        #                      tf.keras.layers.Concatenate(axis=-1)([forward_end[1], backword_end[1]])]\n",
    "        #     initial_state = [initial_state] * n_stacks\n",
    "\n",
    "        # else:\n",
    "        #     forward_end = s[len(s)//2 - 1]\n",
    "        #     backword_end = s[len(s) - 1]\n",
    "                \n",
    "        #     initial_state = [tf.keras.layers.Concatenate(axis=-1)([forward_end, backword_end])]\n",
    "        #     initial_state = initial_state * n_stacks\n",
    "            \n",
    "    else:\n",
    "        rnn_layer, *s = tf.keras.layers.RNN(\n",
    "            [cell_type(units) for _ in range(n_stacks)],\n",
    "            return_sequences=True,\n",
    "            return_state=True,\n",
    "            name=get_name(name, 'rnn_encoder')\n",
    "        )(embedding)\n",
    "        initial_state = s\n",
    "\n",
    "    \n",
    "    inputs_decoder = tf.keras.layers.Input((None, ), dtype=tf.int32, name=get_name(name, 'input_decoder')) \n",
    "    embedding_dec = tf.keras.layers.Embedding(n_tokens, units, name=get_name(name, 'embedding_decoder'))(inputs_decoder)\n",
    "    \n",
    "    dec_units = 2 * units if bidirectional else units\n",
    "    \n",
    "    rnn = tf.keras.layers.RNN(\n",
    "        [cell_type(dec_units) for _ in range(n_stacks)],\n",
    "        return_sequences=True,\n",
    "        name=get_name(name, 'rnn_decoder')\n",
    "    )(embedding_dec, initial_state=initial_state)\n",
    "    \n",
    "    if attention_flg: \n",
    "        attention_layer =  tf.keras.layers.AdditiveAttention(name=get_name(name, 'attention'))([rnn, rnn_layer])\n",
    "        attention_context = tf.keras.layers.Concatenate(axis=-1, name=get_name(name, 'rnn_and_attention'))([rnn, attention_layer])\n",
    "        output = tf.keras.layers.Dense(n_labels, name=get_name(name, 'output'))(attention_context)\n",
    "    else:   \n",
    "        output = tf.keras.layers.Dense(n_labels, name=get_name(name, 'output'))(rnn)\n",
    "\n",
    "    return tf.keras.Model(inputs=(inputs_encoder, inputs_decoder), outputs=output, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9f242a49-7b43-4ae0-995f-df627af4db01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = get_model(128, tokenizer.vocab_size, tokenizer.vocab_size, n_stacks=1, bidirectional=True, name='Seq2Seq', cell_type=tf.keras.layers.LSTMCell, attention_flg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22612906-7e54-4379-a5dc-ccfa4374037f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Seq2Seq\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Seq2Seq\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Seq2Seq_input_enco… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_embedding_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">6,432,896</span> │ Seq2Seq_input_en… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_input_deco… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_bidirectio… │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ Seq2Seq_embeddin… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_embedding_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">6,432,896</span> │ Seq2Seq_input_de… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_bidirect… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_bidirect… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_rnn_decoder │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ Seq2Seq_embeddin… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RNN</span>)               │                   │            │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ concatenate_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ Seq2Seq_rnn_deco… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>) │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_rnn_and_at… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_rnn_deco… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_output      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">25,781,841</span> │ Seq2Seq_rnn_and_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ <span style=\"color: #00af00; text-decoration-color: #00af00\">50257</span>)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Seq2Seq_input_enco… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_embedding_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m6,432,896\u001b[0m │ Seq2Seq_input_en… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_input_deco… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_bidirectio… │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │    \u001b[38;5;34m263,168\u001b[0m │ Seq2Seq_embeddin… │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_embedding_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m6,432,896\u001b[0m │ Seq2Seq_input_de… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_bidirect… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_bidirect… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_rnn_decoder │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m394,240\u001b[0m │ Seq2Seq_embeddin… │\n",
       "│ (\u001b[38;5;33mRNN\u001b[0m)               │                   │            │ concatenate_7[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ concatenate_8[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │        \u001b[38;5;34m256\u001b[0m │ Seq2Seq_rnn_deco… │\n",
       "│ (\u001b[38;5;33mAdditiveAttention\u001b[0m) │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_rnn_and_at… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_rnn_deco… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_output      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │ \u001b[38;5;34m25,781,841\u001b[0m │ Seq2Seq_rnn_and_… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │ \u001b[38;5;34m50257\u001b[0m)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,305,297</span> (149.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m39,305,297\u001b[0m (149.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,305,297</span> (149.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m39,305,297\u001b[0m (149.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a792820b-eac2-4374-9397-5d6800b3d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(input_ru, input_en), output_en, mask = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a53fefcf-2afe-4cd4-ac6a-0245b9293285",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 32), dtype=int32, numpy=\n",
       " array([[  140,   252, 22177, ..., 50256, 50256, 50256],\n",
       "        [  140,   253, 21169, ...,   220, 21727, 20375],\n",
       "        [  140,    94, 43666, ..., 50256, 50256, 50256],\n",
       "        ...,\n",
       "        [  140,   255, 20375, ..., 45367, 12466,   120],\n",
       "        [  140,    94, 25443, ...,   220,   141,   235],\n",
       "        [  140,   242, 16142, ..., 15166, 21727, 20375]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(64, 15), dtype=int32, numpy=\n",
       " array([[50256,  1544, 21893,   757,    13, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,  5703,  2666,   340,   319,   616,  6915,    13, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,  1858,   338,   645,   779, 13774,   625,   599,  2326,\n",
       "          7545,    13, 50256, 50256, 50256, 50256],\n",
       "        [50256,    40, 13030,  4186,   407,   284,  2652,   503,  2739,\n",
       "           379,  1755,    13, 50256, 50256, 50256],\n",
       "        [50256,  6090,   345,  3708, 10107,    30, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,  5195,   836,   470,   345,   467,   717,    30, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,  5492,  1011,  1337,   286,   616,  1641,    13, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,    40,  1183,  1949,   284,   869,  4186,   757,    13,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,  1639,   804, 46400,    13, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,    40,  1422,   470,   765,   284,   466,   326,   326,\n",
       "           835,    13, 50256, 50256, 50256, 50256],\n",
       "        [50256,  1639,  1549,  1365,  1560,   607,  2582,    13, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256, 13787,   318,   257,  5863, 18560, 34537,    13, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,    40,  1297,  4186,   314,  2227,   284,  4545,  4141,\n",
       "            13, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256, 25324,  3397,   389,   407, 13795,   284,  1561,   546,\n",
       "           511,   898,  1751,    13, 50256, 50256],\n",
       "        [50256,    47,   454,  4186,   617,  7545,    13, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256, 13787,  2476,   284, 13502,  8242,    13, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256, 24814,  5235,   318,   257, 22158,  3240,    13, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,  3347,   468,   683,   739,   607, 15683,    13, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256, 13787,   318,  1972,  1365,   379,  5059,    13, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,  1544,  5818,   470, 47358,   502,   736,    13, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,    40,  1101,  1165, 10032,   284,  4483,    13, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,  2990,   389,   257,  4167,    12, 33983,   661,    13,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,   464, 10577,   547,  2111,   284,  6654,    13, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,  1026,   373,   257,  2408,  2551,    13, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256, 24119,   373,   938,  1775,  1972,   656,  4186,   338,\n",
       "          4038,    13, 50256, 50256, 50256, 50256],\n",
       "        [50256,  1639,   389,   257, 14015,    13, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,    40,  1549,   467,  3589,    11,   475,   314,   836,\n",
       "           470,   423,   597,   640,    13, 50256],\n",
       "        [50256,  1135,  1549,  1365,   651,  2067,  1909,    13, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256, 13787,   468,  1239,   550,   881,  1637,    13, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,  1026,  2125,   470,  1165,  2739,   329,   345,    13,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,  1639,   760,   428,  2125,   470,  3306,    13, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,  1639,  1549,  1365,   651,   617,  3993,    13, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,  1135,  5839,   345,   257,  1755,  2971,   523,   345,\n",
       "          3636,   470,   307,  7787,   284,  3993],\n",
       "        [50256,    40,  1464,  2227,   284,   766,   345,    13, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,    40,   836,   470,   765,   284,  1394,  1804,   428,\n",
       "            13, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,    32,  5398,   561,  1239,   466,   884,   257,  1517,\n",
       "            13, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256, 13787,   318,  6155,  2157,  5335,    13, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,  8491,   345,   991,  8805,   379,   502,    30, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256, 11980,   345,   587, 13774,    30, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,  3260,   262,  6290,    11,   262,  4252,  9349,   422,\n",
       "           262, 15114,    13, 50256, 50256, 50256],\n",
       "        [50256, 13787,  1239, 42675,   379,   514,    13, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,    40,  1101,  2045,   329,  1223,  2073,    13, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,  3347,  2227,   607,   898,  2119,    13, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,    40,  1101,  9675,   345,  1265,   502,   326,  1808,\n",
       "            13, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,    37,   378,   318,  4856,   674,  4202,    13, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256, 28065,   373,   257,   922,  1110,    13, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256, 13787,  1444,  5335,   284,  1560,   607,   339,  6151,\n",
       "           607,    13, 50256, 50256, 50256, 50256],\n",
       "        [50256,  3347,   318,  1719,  6891,   783,    13, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,    40,  1053,  5969,  2279,    13, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256, 13787,   318,   257, 22527,  1200,    13, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,  5492,   466,   326,   329,   502,    13, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,    40,   466,   340,   780,   314,   765,   284,    13,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,    40,  1101, 31856,   284, 11875,    13, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,  3646,  1187,   761,   257,  1256,   286,  1660,    13,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,    40,   836,   470,   892,   345,  1549,   307,  1498,\n",
       "           284,   466,   326,    13, 50256, 50256],\n",
       "        [50256,    40,  3181,   345, 11464,   422,  2807,    13, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,   464,   582,  4978,   262,  2576,   416,   262, 15980,\n",
       "            13, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,  1026,   338,  2739,  1541,    13,  1514,  1363,    13,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,  3666,  1995,  1107,  2227,   502,   284,  1716,   257,\n",
       "          6253,    13, 50256, 50256, 50256, 50256],\n",
       "        [50256,  1026,   338,   262,   717, 27737,  1110,   287,   257,\n",
       "           890,   640,    11,   523,   262,  8242],\n",
       "        [50256,    40,  1101,   262,  6478,    13, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,  3792,   326,   477,   345,   821,  1016,   284,  1560,\n",
       "           502,    30, 50256, 50256, 50256, 50256],\n",
       "        [50256,    40,  4719,   326,  4186,   750,   326, 16464,    13,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256],\n",
       "        [50256,  1026,   338,   416,   645,  1724,  2562,   284,  4958,\n",
       "           257,  3215,  3303,    13, 50256, 50256]], dtype=int32)>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ru, input_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "034f1cee-5560-4e95-8d20-4f3851191159",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 15, 50257), dtype=float32, numpy=\n",
       "array([[[-2.46271607e-03, -9.56725096e-04, -1.77378696e-03, ...,\n",
       "          8.25832249e-04, -3.62789142e-03,  5.47599397e-04],\n",
       "        [-2.14463286e-03, -6.28471025e-04, -1.71366613e-03, ...,\n",
       "          3.79801961e-04, -2.88090599e-03,  6.68503926e-04],\n",
       "        [-1.29296537e-03, -1.77024020e-04, -1.26775319e-03, ...,\n",
       "          6.90211542e-04, -1.79957598e-03,  7.09687243e-04],\n",
       "        ...,\n",
       "        [-2.59824505e-04, -2.59114109e-04, -2.51226639e-03, ...,\n",
       "          2.00330094e-03,  6.10027462e-04, -8.61629087e-04],\n",
       "        [-2.41230096e-04, -2.97095423e-04, -2.58331117e-03, ...,\n",
       "          2.08623358e-03,  6.70696667e-04, -9.04475746e-04],\n",
       "        [-2.24289164e-04, -3.25460715e-04, -2.64031300e-03, ...,\n",
       "          2.15441897e-03,  7.22449506e-04, -9.37287114e-04]],\n",
       "\n",
       "       [[ 5.75040991e-04,  6.76668016e-04, -3.08478280e-04, ...,\n",
       "          7.12696696e-04,  9.75751100e-05,  1.20589568e-04],\n",
       "        [-1.15868112e-04,  1.59674324e-04, -5.04133757e-04, ...,\n",
       "          3.79788835e-04, -2.76357052e-04,  9.80093610e-05],\n",
       "        [ 5.51485806e-04,  3.11909535e-04,  2.17352193e-04, ...,\n",
       "          6.74446812e-04,  2.25932527e-05, -1.00158853e-04],\n",
       "        ...,\n",
       "        [ 3.80659476e-05,  2.77804211e-05, -1.87770254e-03, ...,\n",
       "          1.78295211e-03,  1.02646986e-03, -5.72146324e-04],\n",
       "        [-3.32928030e-05, -5.20784233e-05, -2.08370690e-03, ...,\n",
       "          1.91710051e-03,  1.02731632e-03, -6.81475562e-04],\n",
       "        [-8.43064045e-05, -1.21235236e-04, -2.24866462e-03, ...,\n",
       "          2.02738517e-03,  1.02408265e-03, -7.66197802e-04]],\n",
       "\n",
       "       [[-1.79066742e-03,  2.34536536e-04, -1.61850126e-03, ...,\n",
       "          6.04890636e-04, -2.55613774e-03,  8.56907223e-04],\n",
       "        [-7.97467423e-04, -4.18788695e-05, -1.09364837e-03, ...,\n",
       "          6.08213595e-05, -2.18351162e-03,  3.93592491e-04],\n",
       "        [-1.78139133e-04, -2.16379325e-04, -8.12418526e-04, ...,\n",
       "          5.25405048e-04, -1.22309302e-03,  3.63558618e-04],\n",
       "        ...,\n",
       "        [ 1.42868783e-04,  1.41848926e-04, -9.94834583e-04, ...,\n",
       "          8.27112584e-04,  2.61626556e-04,  3.25206143e-04],\n",
       "        [ 8.26327596e-06,  1.03096856e-04, -1.32299482e-03, ...,\n",
       "          1.08765764e-03,  4.89282829e-04,  2.52809259e-05],\n",
       "        [-7.60453404e-05,  4.14271199e-05, -1.60066027e-03, ...,\n",
       "          1.32001925e-03,  6.37395075e-04, -2.06549594e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 3.16676858e-04,  4.08628955e-04, -6.28013164e-04, ...,\n",
       "          9.26703447e-04, -5.79695916e-05,  1.80580886e-04],\n",
       "        [ 2.27229946e-04,  2.36491003e-04, -6.26918976e-04, ...,\n",
       "          1.13333389e-03,  1.76024507e-04,  5.63617796e-04],\n",
       "        [-4.85742901e-04,  5.52248966e-04, -4.59910778e-04, ...,\n",
       "          5.88782190e-04,  2.16003085e-04,  5.39039436e-04],\n",
       "        ...,\n",
       "        [ 2.77054380e-04,  9.10002855e-04, -8.88750190e-04, ...,\n",
       "          1.32841489e-03,  6.31695730e-04,  4.01120080e-04],\n",
       "        [ 1.02946186e-04,  7.08425883e-04, -1.26078643e-03, ...,\n",
       "          1.53979694e-03,  8.06405209e-04,  8.43587331e-05],\n",
       "        [-1.53135043e-05,  5.25069889e-04, -1.57017901e-03, ...,\n",
       "          1.71915826e-03,  9.10081202e-04, -1.77885406e-04]],\n",
       "\n",
       "       [[ 1.11912272e-03,  1.21124875e-04,  9.60913239e-05, ...,\n",
       "          7.06768129e-04,  3.74120777e-04,  1.05036830e-03],\n",
       "        [ 5.31006022e-04,  2.17962282e-04,  3.90508969e-04, ...,\n",
       "          2.65319250e-04,  3.12238699e-04,  7.79533701e-04],\n",
       "        [-1.06688531e-04,  1.76892645e-04,  6.69534667e-04, ...,\n",
       "          5.99214545e-05, -1.88585356e-04,  1.16752414e-03],\n",
       "        ...,\n",
       "        [-2.82829365e-04,  8.78455758e-05, -1.73949683e-03, ...,\n",
       "          1.61940965e-03,  8.43487564e-04, -2.94369529e-04],\n",
       "        [-2.92383309e-04, -3.46553861e-06, -1.95808732e-03, ...,\n",
       "          1.79624232e-03,  8.80378764e-04, -4.67051927e-04],\n",
       "        [-2.91973760e-04, -8.33309896e-05, -2.13499437e-03, ...,\n",
       "          1.94107415e-03,  9.06044850e-04, -6.03527704e-04]],\n",
       "\n",
       "       [[ 9.14666743e-04,  7.80738425e-04, -2.57978099e-04, ...,\n",
       "          5.58278058e-04,  4.50872525e-04,  1.53972651e-04],\n",
       "        [ 1.03014999e-03,  3.67188681e-04, -3.83046456e-04, ...,\n",
       "          6.12353266e-04,  7.65205041e-05,  8.94411351e-05],\n",
       "        [ 1.17012742e-03,  2.51268211e-05, -2.44938390e-04, ...,\n",
       "          9.29563132e-04,  5.75492450e-04,  1.99916860e-04],\n",
       "        ...,\n",
       "        [ 2.34317326e-04,  7.04255363e-05,  1.46131395e-04, ...,\n",
       "          2.11387131e-04, -1.65619349e-04,  7.40244985e-04],\n",
       "        [ 3.35373625e-05,  2.03532429e-04, -4.45547310e-04, ...,\n",
       "          5.99836465e-04,  2.33424013e-04,  2.94357946e-04],\n",
       "        [-1.03438448e-04,  2.25468830e-04, -9.21651954e-04, ...,\n",
       "          9.33472300e-04,  4.89832019e-04, -3.48831527e-05]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models([(input_ru, input_en)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c5d763-e07d-48cd-a539-987a99ad74a7",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2006bfa0-eee3-439d-899d-7612e7a95a90",
   "metadata": {},
   "source": [
    "Train your model using teacher forcing. The idea is that the model predicts the next token that should follow, so one part of the model (called encoder) reads the text and output some state containing information about the text read. The other part of the model (called decoder) reads and already generated text (or in case of the teacher forcing the expected output) and predicts the next token for each one. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a200401a-9323-4874-8d25-778bba1a9a25",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5256a57-4d00-4461-8450-afa9e2f4255f",
   "metadata": {},
   "source": [
    "При обучении моделей на выходе энкодера бралось только последнее состояние и \"размножалось\" в количестве используемых ячеек и подавалось на вход декодеру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b5fe6f43-5e20-4a9b-a3d7-5a1f7097dd8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Seq2Seq\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Seq2Seq\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Seq2Seq_input_enco… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_embedding_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">6,432,896</span> │ Seq2Seq_input_en… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_input_deco… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_bidirectio… │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">526,336</span> │ Seq2Seq_embeddin… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_embedding_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">6,432,896</span> │ Seq2Seq_input_de… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_26      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_bidirect… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_27      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_bidirect… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_28      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_bidirect… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_29      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_bidirect… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_rnn_decoder │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">919,552</span> │ Seq2Seq_embeddin… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RNN</span>)               │                   │            │ concatenate_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ concatenate_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ concatenate_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ concatenate_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_output      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12,916,049</span> │ Seq2Seq_rnn_deco… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ <span style=\"color: #00af00; text-decoration-color: #00af00\">50257</span>)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Seq2Seq_input_enco… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_embedding_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m6,432,896\u001b[0m │ Seq2Seq_input_en… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_input_deco… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_bidirectio… │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m526,336\u001b[0m │ Seq2Seq_embeddin… │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_embedding_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m6,432,896\u001b[0m │ Seq2Seq_input_de… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_26      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_bidirect… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_27      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_bidirect… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_28      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_bidirect… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_29      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_bidirect… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_rnn_decoder │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m919,552\u001b[0m │ Seq2Seq_embeddin… │\n",
       "│ (\u001b[38;5;33mRNN\u001b[0m)               │                   │            │ concatenate_26[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ concatenate_27[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ concatenate_28[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ concatenate_29[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_output      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │ \u001b[38;5;34m12,916,049\u001b[0m │ Seq2Seq_rnn_deco… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │ \u001b[38;5;34m50257\u001b[0m)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,227,729</span> (103.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m27,227,729\u001b[0m (103.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,227,729</span> (103.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m27,227,729\u001b[0m (103.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1 = get_model(128,\n",
    "                   tokenizer.vocab_size,\n",
    "                   tokenizer.vocab_size,\n",
    "                   n_stacks=2,\n",
    "                   bidirectional=True,\n",
    "                   name='Seq2Seq',\n",
    "                   cell_type=tf.keras.layers.LSTMCell,\n",
    "                   attention_flg=False\n",
    ")\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9510384-cfb3-46d2-8e15-ecf099e32f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c3b2a51-336c-42b7-b564-a201a001f48e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training: Seq2Seq\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731027567.663516    1287 service.cc:145] XLA service 0x14f89350 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1731027567.663555    1287 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2024-11-08 10:59:27.765410: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "W0000 00:00:1731027568.117567    1287 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "2024-11-08 10:59:28.305712: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731027569.077644    2091 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_173', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731027569.489650    2097 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_173', 1748 bytes spill stores, 2168 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731027570.541249    2093 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_177', 280 bytes spill stores, 264 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731027570.927827    2100 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_175', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731027570.958736    2092 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_175', 1760 bytes spill stores, 2180 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731027574.260997    1287 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2004/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5307 - loss: 2.8590"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1731027716.426898    1289 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "I0000 00:00:1731027717.323745    2845 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_177', 44 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731027718.138031    2844 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_177', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731027718.246785    2847 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_174', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731027718.763870    2840 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_175', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731027718.881546    2851 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_175', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731027718.976943    2849 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_175', 92 bytes spill stores, 92 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731027719.248136    2842 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_173', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731027719.513075    2839 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_175', 324 bytes spill stores, 792 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731027719.573720    2847 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_173', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731027719.757600    2842 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_173', 92 bytes spill stores, 92 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731027719.916905    2844 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_173', 348 bytes spill stores, 788 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 74ms/step - accuracy: 0.5307 - loss: 2.8584\n",
      "Epoch 2/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 74ms/step - accuracy: 0.7021 - loss: 1.5326\n",
      "Epoch 3/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 76ms/step - accuracy: 0.6467 - loss: 1.1980\n",
      "Epoch 4/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 76ms/step - accuracy: 0.6009 - loss: 1.0139\n",
      "Epoch 5/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 77ms/step - accuracy: 0.5651 - loss: 0.8971\n",
      "Epoch 6/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 79ms/step - accuracy: 0.5516 - loss: 0.8157\n",
      "Epoch 7/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 78ms/step - accuracy: 0.5298 - loss: 0.7544\n",
      "Epoch 8/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 78ms/step - accuracy: 0.5368 - loss: 0.7066\n",
      "Epoch 9/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 77ms/step - accuracy: 0.5253 - loss: 0.6667\n",
      "Epoch 10/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 78ms/step - accuracy: 0.5279 - loss: 0.6336\n",
      "Epoch 11/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 78ms/step - accuracy: 0.5331 - loss: 0.6051\n",
      "Epoch 12/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 78ms/step - accuracy: 0.5295 - loss: 0.5803\n",
      "Epoch 13/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 78ms/step - accuracy: 0.5291 - loss: 0.5583\n",
      "Epoch 14/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 78ms/step - accuracy: 0.5305 - loss: 0.5387\n",
      "Epoch 15/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 79ms/step - accuracy: 0.5333 - loss: 0.5210\n"
     ]
    }
   ],
   "source": [
    "print(f'model training: {model1.name}')\n",
    "history_1 = model1.fit(train_dataset, batch_size=256, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9d4e76a-ac7d-48cb-99e0-d7948ded2ce8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дообучение модели\n",
      "model training: Seq2Seq\n",
      "Epoch 1/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 73ms/step - accuracy: 0.5383 - loss: 0.5051\n",
      "Epoch 2/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 75ms/step - accuracy: 0.5397 - loss: 0.4904\n",
      "Epoch 3/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 77ms/step - accuracy: 0.5421 - loss: 0.4773\n",
      "Epoch 4/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 78ms/step - accuracy: 0.5446 - loss: 0.4651\n",
      "Epoch 5/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 78ms/step - accuracy: 0.5474 - loss: 0.4537\n",
      "Epoch 6/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 78ms/step - accuracy: 0.5528 - loss: 0.4429\n",
      "Epoch 7/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 79ms/step - accuracy: 0.5532 - loss: 0.4329\n",
      "Epoch 8/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 78ms/step - accuracy: 0.5543 - loss: 0.4234\n",
      "Epoch 9/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 79ms/step - accuracy: 0.5571 - loss: 0.4148\n",
      "Epoch 10/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 79ms/step - accuracy: 0.5584 - loss: 0.4068\n",
      "Epoch 11/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 78ms/step - accuracy: 0.5610 - loss: 0.3992\n",
      "Epoch 12/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 78ms/step - accuracy: 0.5653 - loss: 0.3924\n",
      "Epoch 13/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 78ms/step - accuracy: 0.5618 - loss: 0.3856\n",
      "Epoch 14/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 78ms/step - accuracy: 0.5621 - loss: 0.3795\n",
      "Epoch 15/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 78ms/step - accuracy: 0.5734 - loss: 0.3736\n"
     ]
    }
   ],
   "source": [
    "print('Дообучение модели')\n",
    "print(f'model training: {model1.name}')\n",
    "history_1 = model1.fit(train_dataset, batch_size=256, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5378a04-90b6-4ada-85c7-541643da8567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Веса модели 30_new_LSTM_Seq2Seq сохранены\n"
     ]
    }
   ],
   "source": [
    "print('-'*30)\n",
    "model1.save_weights(f'30_new_LSTM_{model1.name}.weights.h5')\n",
    "print(f'Веса модели 30_new_LSTM_{model1.name} сохранены')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebfe9fa-fd96-4cb0-a575-e9212de2d5b8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "81d41403-2ae2-4206-8858-5d368daaf728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Seq2Seq\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Seq2Seq\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Seq2Seq_input_enco… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_embedding_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12,865,792</span> │ Seq2Seq_input_en… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_input_deco… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_bidirectio… │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,101,248</span> │ Seq2Seq_embeddin… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_embedding_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12,865,792</span> │ Seq2Seq_input_de… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_30      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_bidirect… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_31      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_bidirect… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_32      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_bidirect… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_33      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_bidirect… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_rnn_decoder │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,674,112</span> │ Seq2Seq_embeddin… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RNN</span>)               │                   │            │ concatenate_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ concatenate_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ concatenate_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ concatenate_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ Seq2Seq_rnn_deco… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>) │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_rnn_and_at… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_rnn_deco… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_output      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">51,513,425</span> │ Seq2Seq_rnn_and_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ <span style=\"color: #00af00; text-decoration-color: #00af00\">50257</span>)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Seq2Seq_input_enco… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_embedding_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │ \u001b[38;5;34m12,865,792\u001b[0m │ Seq2Seq_input_en… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_input_deco… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_bidirectio… │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │  \u001b[38;5;34m2,101,248\u001b[0m │ Seq2Seq_embeddin… │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_embedding_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │ \u001b[38;5;34m12,865,792\u001b[0m │ Seq2Seq_input_de… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_30      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_bidirect… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_31      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_bidirect… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_32      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_bidirect… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_33      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_bidirect… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_rnn_decoder │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m3,674,112\u001b[0m │ Seq2Seq_embeddin… │\n",
       "│ (\u001b[38;5;33mRNN\u001b[0m)               │                   │            │ concatenate_30[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ concatenate_31[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ concatenate_32[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ concatenate_33[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ Seq2Seq_rnn_deco… │\n",
       "│ (\u001b[38;5;33mAdditiveAttention\u001b[0m) │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_rnn_and_at… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_rnn_deco… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m1024\u001b[0m)             │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_output      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │ \u001b[38;5;34m51,513,425\u001b[0m │ Seq2Seq_rnn_and_… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │ \u001b[38;5;34m50257\u001b[0m)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">83,020,881</span> (316.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m83,020,881\u001b[0m (316.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">83,020,881</span> (316.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m83,020,881\u001b[0m (316.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2 = get_model(256,\n",
    "                   tokenizer.vocab_size,\n",
    "                   tokenizer.vocab_size,\n",
    "                   n_stacks=2,\n",
    "                   bidirectional=True,\n",
    "                   name='Seq2Seq',\n",
    "                   cell_type=tf.keras.layers.LSTMCell,\n",
    "                   attention_flg=True\n",
    ")\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63179db5-6d8d-4530-968f-f7ef33b95293",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "843f513e-c2b8-4e33-b427-87fca104189b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training: Seq2Seq\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1730986736.964115   37220 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2004/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.6026 - loss: 2.5358"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1730987184.238713   37222 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 223ms/step - accuracy: 0.6026 - loss: 2.5353\n",
      "Epoch 2/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 222ms/step - accuracy: 0.7253 - loss: 1.3815\n",
      "Epoch 3/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 222ms/step - accuracy: 0.6500 - loss: 1.0143\n",
      "Epoch 4/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 222ms/step - accuracy: 0.5907 - loss: 0.8181\n",
      "Epoch 5/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 222ms/step - accuracy: 0.5883 - loss: 0.6966\n",
      "Epoch 6/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 222ms/step - accuracy: 0.5864 - loss: 0.6097\n",
      "Epoch 7/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 222ms/step - accuracy: 0.5854 - loss: 0.5447\n",
      "Epoch 8/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 222ms/step - accuracy: 0.5951 - loss: 0.4915\n",
      "Epoch 9/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 222ms/step - accuracy: 0.6004 - loss: 0.4482\n",
      "Epoch 10/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 222ms/step - accuracy: 0.6105 - loss: 0.4100\n",
      "Epoch 11/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 222ms/step - accuracy: 0.6119 - loss: 0.3769\n",
      "Epoch 12/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 222ms/step - accuracy: 0.6198 - loss: 0.3483\n",
      "Epoch 13/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 222ms/step - accuracy: 0.6195 - loss: 0.3242\n",
      "Epoch 14/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 223ms/step - accuracy: 0.6206 - loss: 0.3002\n",
      "Epoch 15/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 223ms/step - accuracy: 0.6247 - loss: 0.2792\n"
     ]
    }
   ],
   "source": [
    "print(f'model training: {model2.name}')\n",
    "history_2 = model2.fit(train_dataset, batch_size=256, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c6956f9-f46b-4f56-ae5e-2370c0a4b7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дообучение дополнительных 15 эпох модели\n",
      "model training: Seq2Seq\n",
      "Epoch 1/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 219ms/step - accuracy: 0.6333 - loss: 0.2608\n",
      "Epoch 2/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 214ms/step - accuracy: 0.6311 - loss: 0.2457\n",
      "Epoch 3/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 198ms/step - accuracy: 0.6318 - loss: 0.2295\n",
      "Epoch 4/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 193ms/step - accuracy: 0.6354 - loss: 0.2155\n",
      "Epoch 5/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 193ms/step - accuracy: 0.6357 - loss: 0.2040\n",
      "Epoch 6/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 193ms/step - accuracy: 0.6340 - loss: 0.1922\n",
      "Epoch 7/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 219ms/step - accuracy: 0.6430 - loss: 0.1825\n",
      "Epoch 8/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 222ms/step - accuracy: 0.6461 - loss: 0.1725\n",
      "Epoch 9/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 223ms/step - accuracy: 0.6482 - loss: 0.1649\n",
      "Epoch 10/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 223ms/step - accuracy: 0.6440 - loss: 0.1571\n",
      "Epoch 11/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 223ms/step - accuracy: 0.6529 - loss: 0.1494\n",
      "Epoch 12/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 223ms/step - accuracy: 0.6482 - loss: 0.1425\n",
      "Epoch 13/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 223ms/step - accuracy: 0.6504 - loss: 0.1367\n",
      "Epoch 14/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 223ms/step - accuracy: 0.6461 - loss: 0.1307\n",
      "Epoch 15/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 223ms/step - accuracy: 0.6519 - loss: 0.1255\n"
     ]
    }
   ],
   "source": [
    "print('Дообучение дополнительных 15 эпох модели')\n",
    "print(f'model training: {model2.name}')\n",
    "history_2 = model2.fit(train_dataset, batch_size=256, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eece1137-da8f-47d9-97f2-14d89375ebac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Веса модели 30_new_attention_LSTM_Seq2Seq сохранены\n"
     ]
    }
   ],
   "source": [
    "print('-'*30)\n",
    "model2.save_weights(f'30_new_attention_LSTM_{model2.name}.weights.h5')\n",
    "print(f'Веса модели 30_new_attention_LSTM_{model2.name} сохранены')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531ec0af-5fa8-4b08-a263-e32e86680e7f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d0daa45b-d033-4d80-90be-690ee75f2686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Seq2Seq_attention_GRUCell\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Seq2Seq_attention_GRUCell\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Seq2Seq_attention_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">6,432,896</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">792,576</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">6,432,896</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_38      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_39      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_40      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_41      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,480,704</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RNN</span>)               │                   │            │ concatenate_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ concatenate_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ concatenate_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ concatenate_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>) │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">25,781,841</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ <span style=\"color: #00af00; text-decoration-color: #00af00\">50257</span>)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Seq2Seq_attention_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m6,432,896\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m792,576\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m6,432,896\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_38      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_39      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_40      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_41      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m1,480,704\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mRNN\u001b[0m)               │                   │            │ concatenate_38[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ concatenate_39[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ concatenate_40[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ concatenate_41[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │        \u001b[38;5;34m256\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mAdditiveAttention\u001b[0m) │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │ \u001b[38;5;34m25,781,841\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │ \u001b[38;5;34m50257\u001b[0m)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,921,169</span> (156.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m40,921,169\u001b[0m (156.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,921,169</span> (156.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m40,921,169\u001b[0m (156.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model3 = get_model(128,\n",
    "                   tokenizer.vocab_size,\n",
    "                   tokenizer.vocab_size,\n",
    "                   n_stacks=4,\n",
    "                   bidirectional=True,\n",
    "                   name='Seq2Seq_attention_GRUCell',\n",
    "                   cell_type=tf.keras.layers.GRUCell,\n",
    "                   attention_flg=True\n",
    ")\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dfce1dcb-3cef-44dd-bbf9-97533673629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5680457d-0e59-428c-a35f-c18e07f3f643",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training: Seq2Seq_attention_GRUCell\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1731000000.546222   37219 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "I0000 00:00:1731000001.852334   97356 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_488', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731000002.680821   97362 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_488', 112 bytes spill stores, 112 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731000003.363254   97361 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_472', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731000003.528791   97364 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot', 128 bytes spill stores, 128 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731000003.552923   97354 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_475', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731000003.965203   97363 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_475', 112 bytes spill stores, 112 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2004/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.4927 - loss: 2.7459"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1731000287.587403   37217 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "I0000 00:00:1731000289.279472   98595 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_475', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731000289.410082   98597 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot', 28 bytes spill stores, 28 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731000289.761581   98588 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_475', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731000289.787169   98601 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731000290.311107   98594 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_488', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731000291.514149   98591 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_472', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 143ms/step - accuracy: 0.4928 - loss: 2.7453\n",
      "Epoch 2/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 141ms/step - accuracy: 0.6504 - loss: 1.4874\n",
      "Epoch 3/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 141ms/step - accuracy: 0.5592 - loss: 1.1661\n",
      "Epoch 4/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 141ms/step - accuracy: 0.5272 - loss: 0.9871\n",
      "Epoch 5/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 141ms/step - accuracy: 0.5313 - loss: 0.8734\n",
      "Epoch 6/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 142ms/step - accuracy: 0.5581 - loss: 0.7947\n",
      "Epoch 7/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 141ms/step - accuracy: 0.5620 - loss: 0.7379\n",
      "Epoch 8/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 141ms/step - accuracy: 0.5624 - loss: 0.6966\n",
      "Epoch 9/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 141ms/step - accuracy: 0.5737 - loss: 0.6638\n",
      "Epoch 10/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 141ms/step - accuracy: 0.5669 - loss: 0.6360\n",
      "Epoch 11/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 141ms/step - accuracy: 0.5642 - loss: 0.6123\n",
      "Epoch 12/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 141ms/step - accuracy: 0.5728 - loss: 0.5916\n",
      "Epoch 13/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 141ms/step - accuracy: 0.5980 - loss: 0.5735\n",
      "Epoch 14/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 141ms/step - accuracy: 0.6081 - loss: 0.5562\n",
      "Epoch 15/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 141ms/step - accuracy: 0.6207 - loss: 0.5439\n"
     ]
    }
   ],
   "source": [
    "print(f'model training: {model3.name}')\n",
    "history_3 = model3.fit(train_dataset, batch_size=256, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e733ba0d-c105-4076-a731-2e8603363240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дообучение дополнительных 15 эпох модели\n",
      "model training: Seq2Seq_attention_GRUCell\n",
      "Epoch 1/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 141ms/step - accuracy: 0.6260 - loss: 0.5301\n",
      "Epoch 2/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 141ms/step - accuracy: 0.6333 - loss: 0.5150\n",
      "Epoch 3/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 141ms/step - accuracy: 0.6317 - loss: 0.5041\n",
      "Epoch 4/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 141ms/step - accuracy: 0.6343 - loss: 0.4943\n",
      "Epoch 5/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 140ms/step - accuracy: 0.6399 - loss: 0.4855\n",
      "Epoch 6/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 141ms/step - accuracy: 0.6351 - loss: 0.4802\n",
      "Epoch 7/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 142ms/step - accuracy: 0.6452 - loss: 0.4735\n",
      "Epoch 8/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 142ms/step - accuracy: 0.6463 - loss: 0.4641\n",
      "Epoch 9/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 141ms/step - accuracy: 0.6412 - loss: 0.4571\n",
      "Epoch 10/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 141ms/step - accuracy: 0.6396 - loss: 0.4511\n",
      "Epoch 11/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 140ms/step - accuracy: 0.6457 - loss: 0.4448\n",
      "Epoch 12/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 141ms/step - accuracy: 0.6470 - loss: 0.4392\n",
      "Epoch 13/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 141ms/step - accuracy: 0.6523 - loss: 0.4347\n",
      "Epoch 14/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 141ms/step - accuracy: 0.6628 - loss: 0.4304\n",
      "Epoch 15/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 141ms/step - accuracy: 0.6582 - loss: 0.4261\n"
     ]
    }
   ],
   "source": [
    "print('Дообучение дополнительных 15 эпох модели')\n",
    "print(f'model training: {model3.name}')\n",
    "history_3 = model3.fit(train_dataset, batch_size=256, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7eda9c00-dd55-4da4-af6d-df6041fea343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Веса модели 30_new_Seq2Seq_attention_GRUCell сохранены\n"
     ]
    }
   ],
   "source": [
    "print('-'*30)\n",
    "model3.save_weights(f'30_new_{model3.name}.weights.h5')\n",
    "print(f'Веса модели 30_new_{model3.name} сохранены')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c96e4a0-7c9c-4d1c-97f6-a8d3846b4fde",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7f3475-22b9-47b4-824c-7ebc758b75a2",
   "metadata": {},
   "source": [
    "Make a function for text translation. Translate some text and evaluate model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602f831b-9ddd-4070-ba8f-b7b16bc26463",
   "metadata": {},
   "source": [
    "Take note that your model is set for training. During the inference process you will have to use parts of the model independently (including the RNN cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0a32f4dc-3c53-426d-bf67-35b1efe2bbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(\n",
    "    text: str,\n",
    "    tokenizer: Tokenizer,\n",
    "    model: keras.Model,\n",
    "    max_len: int = 20,\n",
    "    type_cell: str = 'LSTM',\n",
    "    name_model: str = 'Seq2Seq',\n",
    "    flg_attention: bool = True\n",
    ") -> str:\n",
    "    '''Predicts `text`translation using the `model`.\n",
    "\n",
    "    Arguments:\n",
    "        text: text to be translated\n",
    "        tokenizer: tokenizer to use\n",
    "        model: model ot use\n",
    "        max_len: maximum length of the prediction (in tokens)\n",
    "\n",
    "    Returns:\n",
    "        tranlated text'''\n",
    "\n",
    "    encorder_emm = model.get_layer(f'{name_model}_embedding_encoder')\n",
    "    encoder_rnn = model.get_layer(f'{name_model}_bidirectional')\n",
    "\n",
    "    input_seq =  tokenizer(text, return_tensors='np', add_special_tokens=False)['input_ids'].astype(np.int32)\n",
    "    encoder_outputs, *states = encoder_rnn(encorder_emm(input_seq))\n",
    "\n",
    "    if type_cell == 'LSTM':\n",
    "        forwards = states[len(states) // 2-1]\n",
    "        bacwards = states[len(states) - 1]\n",
    "        initial_state = [tf.keras.ops.concatenate([forwards[0], bacwards[0]], axis=-1),\n",
    "                         tf.keras.ops.concatenate([forwards[1], bacwards[1]], axis=-1),]\n",
    "        initial_state = [initial_state] * (len(states) // 2)\n",
    "    else:\n",
    "        forwards = states[len(states) // 2 - 1]\n",
    "        bacwards = states[len(states) - 1]\n",
    "        initial_state = [tf.keras.ops.concatenate([forwards[0], bacwards[0]], axis=-1)]\n",
    "        initial_state = initial_state * (len(states) // 2)\n",
    "        \n",
    "\n",
    "    target_seq = [tokenizer.pad_token_id]\n",
    "    \n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    decoder_embedding = model.get_layer(f'{name_model}_embedding_decoder')\n",
    "    decoder_rnn = model.get_layer(f'{name_model}_rnn_decoder').cell\n",
    "    decoder_dance = model.get_layer(f'{name_model}_output')\n",
    "    if flg_attention:\n",
    "        attention_layer = model.get_layer(f'{name_model}_attention')\n",
    "        \n",
    "\n",
    "    states = initial_state\n",
    "    for _ in range(max_len):\n",
    "\n",
    "        embedding = decoder_embedding(np.array(target_seq[-1]))\n",
    "        rnn, *states = decoder_rnn(embedding, states)\n",
    "        states = states[0]\n",
    "        if flg_attention:\n",
    "            attention = attention_layer([rnn, encoder_outputs])[0]\n",
    "            rnn = tf.keras.ops.concatenate([rnn, attention], axis=-1)\n",
    "        \n",
    "        output = decoder_dance(rnn)\n",
    "        output_tokens = np.argmax(output.numpy(),axis=-1)[0]\n",
    "\n",
    "        sampled_word = tokenizer.decode(output_tokens)\n",
    "        \n",
    "        if output_tokens == tokenizer.pad_token_id:\n",
    "            break\n",
    "        else:\n",
    "            decoded_sentence += sampled_word\n",
    "        \n",
    "        target_seq[0] = output_tokens\n",
    "\n",
    "    return decoded_sentence.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ab0cba1a-af73-4341-a5e8-5e898b564ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Веса модели 30_new_LSTM_Seq2Seq загружены\n",
      "Веса модели 30_new_attention_LSTM_Seq2Seq загружены\n",
      "Веса модели 30_new_Seq2Seq_attention_GRUCell загружены\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dron46/anaconda3/envs/tf/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 84 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model1.load_weights(f'30_new_LSTM_{model1.name}.weights.h5')\n",
    "print(f'Веса модели 30_new_LSTM_{model1.name} загружены')\n",
    "model2.load_weights(f'30_new_attention_LSTM_{model2.name}.weights.h5')\n",
    "print(f'Веса модели 30_new_attention_LSTM_{model2.name} загружены')\n",
    "model3.load_weights(f'30_new_{model3.name}.weights.h5')\n",
    "print(f'Веса модели 30_new_{model3.name} загружены')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "03441892-cbd5-46a6-ad7a-a72d65079478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "texts = ['Я люблю пиво', 'Я хочу в отпуск', 'Суббота лучший день для учёбы', 'Котик уснул на кровате']\n",
    "translates_texts = []\n",
    "for text in texts:\n",
    "    translates_texts.append(translate(text, tokenizer, model1, 16, type_cell='LSTM', name_model='Seq2Seq', flg_attention=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b4e29e92-8063-42a7-af5f-00b4c3f5f39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like beer.',\n",
       " 'I want to go to the bus stop.',\n",
       " 'Saturday is the season for learning to work.',\n",
       " 'The cat fell asleep in the room.']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translates_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "669467ae-225b-4613-acbd-170982e3785a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How when every every every has has arewise the the the the the'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e8a0e445-6779-4e34-9dfd-5d25828b3440",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "texts = ['Я люблю пиво', 'Я хочу в отпуск', 'Суббота лучший день для учёбы', 'Котик уснул на кровати']\n",
    "translates_texts = []\n",
    "for text in texts:\n",
    "    translates_texts.append(translate(text, tokenizer, model2, 16, type_cell='LSTM', name_model='Seq2Seq', flg_attention=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7d3abc83-0974-4384-9dc9-df79053fb00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I love wild beer.',\n",
       " 'I want to go to Mexico.',\n",
       " 'The job is the best day of the year.',\n",
       " 'The cat were asleep on the bed.']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translates_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "805a2e63-dfa7-4390-92d6-30d860b08d16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "texts = ['Я люблю пиво', 'Я хочу в отпуск', 'Суббота лучший день для учёбы', 'Котик уснул на кровати']\n",
    "translates_texts = []\n",
    "for text in texts:\n",
    "    translates_texts.append(translate(text, tokenizer, model3, 16, type_cell='GRU', name_model='Seq2Seq_attention_GRUCell', flg_attention=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d28559b3-6457-4962-975e-0c7c749f2fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like vampire when I drank too much salt.',\n",
       " 'I want to go shopping in my wallet.',\n",
       " 'The best translation is the best of the book.',\n",
       " 'The tub fell to the edge of the mountain.']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translates_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a789944-2dab-4442-b1cd-a9f36b839b50",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3a74b6-bbed-4309-a318-79518beebf9b",
   "metadata": {},
   "source": [
    "# Training and Testing 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191a402a-a16c-498c-8960-d19158dbb753",
   "metadata": {},
   "source": [
    "Исправленные модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0e8bec62-14c4-44f1-89e8-c6bac80662b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Seq2Seq\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Seq2Seq\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Seq2Seq_input_enco… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_embedding_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">6,432,896</span> │ Seq2Seq_input_en… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_input_deco… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_bidirectio… │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">526,336</span> │ Seq2Seq_embeddin… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_embedding_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">6,432,896</span> │ Seq2Seq_input_de… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_42      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_bidirect… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_43      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_bidirect… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_44      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_bidirect… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_45      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_bidirect… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_rnn_decoder │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">919,552</span> │ Seq2Seq_embeddin… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RNN</span>)               │                   │            │ concatenate_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ concatenate_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ concatenate_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ concatenate_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_output      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12,916,049</span> │ Seq2Seq_rnn_deco… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ <span style=\"color: #00af00; text-decoration-color: #00af00\">50257</span>)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Seq2Seq_input_enco… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_embedding_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m6,432,896\u001b[0m │ Seq2Seq_input_en… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_input_deco… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_bidirectio… │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m526,336\u001b[0m │ Seq2Seq_embeddin… │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_embedding_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m6,432,896\u001b[0m │ Seq2Seq_input_de… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_42      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_bidirect… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_43      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_bidirect… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_44      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_bidirect… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_45      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_bidirect… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_rnn_decoder │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m919,552\u001b[0m │ Seq2Seq_embeddin… │\n",
       "│ (\u001b[38;5;33mRNN\u001b[0m)               │                   │            │ concatenate_42[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ concatenate_43[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ concatenate_44[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ concatenate_45[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_output      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │ \u001b[38;5;34m12,916,049\u001b[0m │ Seq2Seq_rnn_deco… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │ \u001b[38;5;34m50257\u001b[0m)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,227,729</span> (103.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m27,227,729\u001b[0m (103.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,227,729</span> (103.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m27,227,729\u001b[0m (103.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1 = get_model(128,\n",
    "                   tokenizer.vocab_size,\n",
    "                   tokenizer.vocab_size,\n",
    "                   n_stacks=2,\n",
    "                   bidirectional=True,\n",
    "                   name='Seq2Seq',\n",
    "                   cell_type=tf.keras.layers.LSTMCell,\n",
    "                   attention_flg=False\n",
    ")\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "255de51c-b647-4ddc-b0dc-0a1595b76e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e97e8b2-1076-479f-aaf6-6843af85d8b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training: Seq2Seq\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731329957.147876   41705 service.cc:145] XLA service 0xe35cfa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1731329957.147973   41705 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2024-11-11 22:59:17.250353: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "W0000 00:00:1731329957.632463   41705 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "2024-11-11 22:59:17.837264: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731329959.001547   41980 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_177', 280 bytes spill stores, 264 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731329960.164700   41989 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_173', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731329960.164746   41984 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_173', 1748 bytes spill stores, 2168 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731329960.455371   41982 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_175', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731329960.721482   41985 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_175', 1760 bytes spill stores, 2180 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731329963.831496   41705 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2004/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5616 - loss: 2.8828"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1731330113.125761   41707 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "I0000 00:00:1731330113.733401   42764 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_173', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731330113.943315   42763 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_173', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731330114.315321   42765 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_175', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731330114.476624   42759 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_175', 92 bytes spill stores, 92 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731330114.520777   42773 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_173', 92 bytes spill stores, 92 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731330114.558197   42762 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_173', 348 bytes spill stores, 788 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731330114.857981   42761 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_175', 324 bytes spill stores, 792 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731330115.106709   42769 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_175', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731330116.194720   42760 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_177', 44 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731330116.347481   42759 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_177', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731330116.689435   42770 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_174', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5616 - loss: 2.8825"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1731330120.189442   41712 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "W0000 00:00:1731330142.050006   41718 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 89ms/step - accuracy: 0.5617 - loss: 2.8822 - val_accuracy: 0.7028 - val_loss: 1.7288\n",
      "Epoch 2/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 90ms/step - accuracy: 0.7160 - loss: 1.6064 - val_accuracy: 0.7368 - val_loss: 1.3516\n",
      "Epoch 3/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 89ms/step - accuracy: 0.6957 - loss: 1.2623 - val_accuracy: 0.6024 - val_loss: 1.1387\n",
      "Epoch 4/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 90ms/step - accuracy: 0.5873 - loss: 1.0506 - val_accuracy: 0.5496 - val_loss: 1.0192\n",
      "Epoch 5/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 90ms/step - accuracy: 0.5641 - loss: 0.9165 - val_accuracy: 0.5348 - val_loss: 0.9477\n",
      "Epoch 6/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 89ms/step - accuracy: 0.5729 - loss: 0.8252 - val_accuracy: 0.5362 - val_loss: 0.9028\n",
      "Epoch 7/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 90ms/step - accuracy: 0.5887 - loss: 0.7574 - val_accuracy: 0.5734 - val_loss: 0.8718\n",
      "Epoch 8/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 90ms/step - accuracy: 0.6146 - loss: 0.7041 - val_accuracy: 0.6587 - val_loss: 0.8538\n",
      "Epoch 9/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 90ms/step - accuracy: 0.6603 - loss: 0.6609 - val_accuracy: 0.7183 - val_loss: 0.8434\n",
      "Epoch 10/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 90ms/step - accuracy: 0.6990 - loss: 0.6250 - val_accuracy: 0.7359 - val_loss: 0.8352\n",
      "Epoch 11/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 90ms/step - accuracy: 0.7228 - loss: 0.5945 - val_accuracy: 0.7409 - val_loss: 0.8288\n",
      "Epoch 12/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 90ms/step - accuracy: 0.7435 - loss: 0.5680 - val_accuracy: 0.7308 - val_loss: 0.8255\n",
      "Epoch 13/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 90ms/step - accuracy: 0.7478 - loss: 0.5445 - val_accuracy: 0.7268 - val_loss: 0.8251\n",
      "Epoch 14/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 90ms/step - accuracy: 0.7486 - loss: 0.5236 - val_accuracy: 0.7230 - val_loss: 0.8261\n",
      "Epoch 15/15\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 90ms/step - accuracy: 0.7467 - loss: 0.5056 - val_accuracy: 0.7210 - val_loss: 0.8270\n"
     ]
    }
   ],
   "source": [
    "print(f'model training: {model1.name}')\n",
    "history_1 = model1.fit(train_dataset, validation_data=test_dataset, batch_size=256, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2dfc2f74-b321-49c0-8917-2389f959fef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Веса модели 12_11_LSTM_Seq2Seq сохранены\n"
     ]
    }
   ],
   "source": [
    "print('-'*30)\n",
    "model1.save_weights(f'12_11_LSTM_{model1.name}.weights.h5')\n",
    "print(f'Веса модели 12_11_LSTM_{model1.name} сохранены')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6369dd79-8c63-4d2f-85c3-11f653ddd635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Веса модели 12_11_LSTM_Seq2Seq загружены\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dron46/anaconda3/envs/tf/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 46 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model1.load_weights(f'12_11_LSTM_{model1.name}.weights.h5')\n",
    "print(f'Веса модели 12_11_LSTM_{model1.name} загружены')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c987efd2-8437-45e9-83b3-eee8c65935cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "texts = ['Я люблю пиво', 'Я хочу в отпуск', 'Суббота лучший день для учёбы', 'Котик уснул на кровате']\n",
    "translates_texts = []\n",
    "for text in texts:\n",
    "    translates_texts.append(translate(text, tokenizer, model1, 16, type_cell='LSTM', name_model='Seq2Seq', flg_attention=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "23c8f148-d1c9-45b5-9c24-ddac152881a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like beer for my children.',\n",
       " 'I want to go to vacation with you.',\n",
       " 'Saturday is for a school than a long time.',\n",
       " 'The cat fell asleep in the bed.']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translates_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bc9fba-ef53-4f41-8aff-6d0585583584",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "90c1015c-fb29-4404-a091-03c557271110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Seq2Seq\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Seq2Seq\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Seq2Seq_input_enco… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_embedding_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12,865,792</span> │ Seq2Seq_input_en… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_input_deco… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_bidirectio… │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,101,248</span> │ Seq2Seq_embeddin… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_embedding_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12,865,792</span> │ Seq2Seq_input_de… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_46      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_bidirect… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_47      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_bidirect… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_48      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_bidirect… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_49      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_bidirect… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_rnn_decoder │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,674,112</span> │ Seq2Seq_embeddin… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RNN</span>)               │                   │            │ concatenate_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ concatenate_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ concatenate_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ concatenate_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ Seq2Seq_rnn_deco… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>) │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_rnn_and_at… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_rnn_deco… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_output      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">51,513,425</span> │ Seq2Seq_rnn_and_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ <span style=\"color: #00af00; text-decoration-color: #00af00\">50257</span>)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Seq2Seq_input_enco… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_embedding_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │ \u001b[38;5;34m12,865,792\u001b[0m │ Seq2Seq_input_en… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_input_deco… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_bidirectio… │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │  \u001b[38;5;34m2,101,248\u001b[0m │ Seq2Seq_embeddin… │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_embedding_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │ \u001b[38;5;34m12,865,792\u001b[0m │ Seq2Seq_input_de… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_46      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_bidirect… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_47      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_bidirect… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_48      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_bidirect… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_49      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_bidirect… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_rnn_decoder │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m3,674,112\u001b[0m │ Seq2Seq_embeddin… │\n",
       "│ (\u001b[38;5;33mRNN\u001b[0m)               │                   │            │ concatenate_46[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ concatenate_47[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ concatenate_48[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ concatenate_49[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ Seq2Seq_rnn_deco… │\n",
       "│ (\u001b[38;5;33mAdditiveAttention\u001b[0m) │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_rnn_and_at… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_rnn_deco… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m1024\u001b[0m)             │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_output      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │ \u001b[38;5;34m51,513,425\u001b[0m │ Seq2Seq_rnn_and_… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │ \u001b[38;5;34m50257\u001b[0m)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">83,020,881</span> (316.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m83,020,881\u001b[0m (316.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">83,020,881</span> (316.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m83,020,881\u001b[0m (316.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2 = get_model(256,\n",
    "                   tokenizer.vocab_size,\n",
    "                   tokenizer.vocab_size,\n",
    "                   n_stacks=2,\n",
    "                   bidirectional=True,\n",
    "                   name='Seq2Seq',\n",
    "                   cell_type=tf.keras.layers.LSTMCell,\n",
    "                   attention_flg=True\n",
    ")\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0e99a634-25dd-4f34-9993-3a2a5e349c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "309dd5d1-fa37-4938-b27b-8308a9119df0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training: Seq2Seq\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731339341.212558   82564 service.cc:145] XLA service 0x1469c690 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1731339341.212833   82564 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2024-11-12 01:35:41.324650: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "W0000 00:00:1731339341.884609   82564 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "2024-11-12 01:35:42.262082: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731339343.516538   83151 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_174', 40 bytes spill stores, 112 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731339344.143039   83147 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_174', 2960 bytes spill stores, 4604 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731339345.025350   83161 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_176', 40 bytes spill stores, 112 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731339345.598894   83146 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_176', 2956 bytes spill stores, 4600 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731339345.709060   83148 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_178', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731339345.726238   83157 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_178', 1748 bytes spill stores, 2168 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731339345.841625   83151 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_4', 212 bytes spill stores, 212 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731339345.938943   83160 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_4', 44 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731339346.170343   83155 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_4', 784 bytes spill stores, 728 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731339351.811182   82564 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2004/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.5959 - loss: 2.5804"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1731339691.066388   82568 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "I0000 00:00:1731339692.302209   84766 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_175', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731339692.666515   84759 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_176', 340 bytes spill stores, 340 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731339692.762005   84767 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_174', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731339693.041722   84768 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_178', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731339693.900384   84767 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_4', 216 bytes spill stores, 216 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731339693.987940   84761 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_176', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731339694.108065   84760 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_176', 48 bytes spill stores, 36 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731339694.499413   84764 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_181', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731339694.571541   84761 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_176', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731339694.705858   84754 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_4', 212 bytes spill stores, 212 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731339694.788529   84766 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_178', 348 bytes spill stores, 788 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731339694.998111   84766 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_178', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731339695.397556   84761 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_178', 92 bytes spill stores, 92 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731339695.503944   84762 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_174', 52 bytes spill stores, 36 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731339695.859367   84759 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_174', 340 bytes spill stores, 340 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731339696.130235   84762 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_174', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.5959 - loss: 2.5801"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1731339701.610509   82573 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "W0000 00:00:1731339745.696962   82570 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 197ms/step - accuracy: 0.5960 - loss: 2.5799 - val_accuracy: 0.7143 - val_loss: 1.4933\n",
      "Epoch 2/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m432s\u001b[0m 216ms/step - accuracy: 0.7107 - loss: 1.3478 - val_accuracy: 0.6940 - val_loss: 1.0470\n",
      "Epoch 3/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 231ms/step - accuracy: 0.6965 - loss: 0.9304 - val_accuracy: 0.7008 - val_loss: 0.8594\n",
      "Epoch 4/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 234ms/step - accuracy: 0.6804 - loss: 0.7274 - val_accuracy: 0.6978 - val_loss: 0.7891\n",
      "Epoch 5/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 235ms/step - accuracy: 0.6748 - loss: 0.6091 - val_accuracy: 0.6637 - val_loss: 0.7582\n",
      "Epoch 6/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 234ms/step - accuracy: 0.6648 - loss: 0.5299 - val_accuracy: 0.6410 - val_loss: 0.7446\n",
      "Epoch 7/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 235ms/step - accuracy: 0.6606 - loss: 0.4717 - val_accuracy: 0.6237 - val_loss: 0.7432\n",
      "Epoch 8/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m468s\u001b[0m 233ms/step - accuracy: 0.6481 - loss: 0.4262 - val_accuracy: 0.6287 - val_loss: 0.7420\n",
      "Epoch 9/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 234ms/step - accuracy: 0.6526 - loss: 0.3887 - val_accuracy: 0.6232 - val_loss: 0.7463\n",
      "Epoch 10/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 235ms/step - accuracy: 0.6584 - loss: 0.3570 - val_accuracy: 0.6095 - val_loss: 0.7557\n"
     ]
    }
   ],
   "source": [
    "print(f'model training: {model2.name}')\n",
    "history_2 = model2.fit(train_dataset, validation_data=test_dataset, batch_size=256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee920afd-fb05-4643-a827-11296525f71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Веса модели 10_LSTM_attention_Seq2Seq сохранены\n"
     ]
    }
   ],
   "source": [
    "print('-'*30)\n",
    "model2.save_weights(f'10_LSTM_attention_{model2.name}.weights.h5')\n",
    "print(f'Веса модели 10_LSTM_attention_{model2.name} сохранены')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7bc80b67-ba02-45ac-a2cd-4e2d74f438f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Веса модели 10_LSTM_attention_Seq2Seq загружены\n"
     ]
    }
   ],
   "source": [
    "model2.load_weights(f'10_LSTM_attention_{model2.name}.weights.h5')\n",
    "print(f'Веса модели 10_LSTM_attention_{model2.name} загружены')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "84bc6862-388b-4da0-a2df-6d2bb70daac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['Я люблю пиво', 'Я хочу в отпуск', 'Суббота лучший день для учёбы', 'Котик уснул на кровати']\n",
    "translates_texts = []\n",
    "for text in texts:\n",
    "    translates_texts.append(translate(text, tokenizer, model2, 16, type_cell='LSTM', name_model='Seq2Seq', flg_attention=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7fd06688-8e07-488e-a5a4-6a608c8a7e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like beer.',\n",
       " 'I want to go to the suburbs.',\n",
       " 'Saturday is the best of the study.',\n",
       " 'The cat fell asleep on the bed.']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translates_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9ddd61-970d-467d-b878-f7675cc389d2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7f2ccc3e-53d6-4142-bf8b-b382a44d5a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Seq2Seq_attention_GRUCell\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Seq2Seq_attention_GRUCell\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Seq2Seq_attention_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">6,432,896</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">792,576</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">6,432,896</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_58      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_59      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_60      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_61      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,480,704</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RNN</span>)               │                   │            │ concatenate_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ concatenate_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ concatenate_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ concatenate_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>) │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">25,781,841</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ <span style=\"color: #00af00; text-decoration-color: #00af00\">50257</span>)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Seq2Seq_attention_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m6,432,896\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m792,576\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m6,432,896\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_58      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_59      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_60      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_61      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m1,480,704\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mRNN\u001b[0m)               │                   │            │ concatenate_58[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ concatenate_59[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ concatenate_60[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ concatenate_61[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │        \u001b[38;5;34m256\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mAdditiveAttention\u001b[0m) │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │ \u001b[38;5;34m25,781,841\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │ \u001b[38;5;34m50257\u001b[0m)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,921,169</span> (156.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m40,921,169\u001b[0m (156.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,921,169</span> (156.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m40,921,169\u001b[0m (156.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model3 = get_model(128,\n",
    "                   tokenizer.vocab_size,\n",
    "                   tokenizer.vocab_size,\n",
    "                   n_stacks=4,\n",
    "                   bidirectional=True,\n",
    "                   name='Seq2Seq_attention_GRUCell',\n",
    "                   cell_type=tf.keras.layers.GRUCell,\n",
    "                   attention_flg=True\n",
    ")\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b5151677-546e-4f91-a021-39b356a5fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8825ab2c-8c53-4836-a368-22fa05a9bd6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training: Seq2Seq_attention_GRUCell\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1731353410.179991   82565 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "I0000 00:00:1731353411.623091  141051 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_482', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731353412.053323  141049 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_482', 112 bytes spill stores, 112 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731353412.177936  141045 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_466', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731353412.471366  141044 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_4', 784 bytes spill stores, 728 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731353412.678943  141051 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_4', 212 bytes spill stores, 212 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731353412.703351  141046 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_469', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731353412.794152  141050 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_4', 44 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731353413.747988  141043 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_469', 112 bytes spill stores, 112 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2004/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.4352 - loss: 2.7425"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1731353672.169149   82569 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "I0000 00:00:1731353673.821259  142194 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_466', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731353674.563160  142181 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_469', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731353674.725728  142195 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_482', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731353674.980168  142182 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_4', 216 bytes spill stores, 216 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731353675.004551  142187 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_4', 212 bytes spill stores, 212 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731353675.632158  142196 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_4', 260 bytes spill stores, 260 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731353676.292660  142192 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_469', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.4352 - loss: 2.7422"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1731353681.698613   82568 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "W0000 00:00:1731353713.298470   82569 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 147ms/step - accuracy: 0.4352 - loss: 2.7420 - val_accuracy: 0.5659 - val_loss: 1.5155\n",
      "Epoch 2/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 141ms/step - accuracy: 0.6767 - loss: 1.3644 - val_accuracy: 0.6768 - val_loss: 1.0777\n",
      "Epoch 3/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 141ms/step - accuracy: 0.7043 - loss: 0.9848 - val_accuracy: 0.6734 - val_loss: 0.9323\n",
      "Epoch 4/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 142ms/step - accuracy: 0.6927 - loss: 0.8183 - val_accuracy: 0.6878 - val_loss: 0.8656\n",
      "Epoch 5/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 141ms/step - accuracy: 0.6832 - loss: 0.7224 - val_accuracy: 0.6258 - val_loss: 0.8314\n",
      "Epoch 6/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 141ms/step - accuracy: 0.6634 - loss: 0.6577 - val_accuracy: 0.5977 - val_loss: 0.8164\n",
      "Epoch 7/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 142ms/step - accuracy: 0.6369 - loss: 0.6100 - val_accuracy: 0.5885 - val_loss: 0.8082\n",
      "Epoch 8/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 142ms/step - accuracy: 0.6317 - loss: 0.5739 - val_accuracy: 0.5797 - val_loss: 0.8025\n",
      "Epoch 9/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 141ms/step - accuracy: 0.6341 - loss: 0.5447 - val_accuracy: 0.5746 - val_loss: 0.8032\n",
      "Epoch 10/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 141ms/step - accuracy: 0.6202 - loss: 0.5210 - val_accuracy: 0.5619 - val_loss: 0.8104\n"
     ]
    }
   ],
   "source": [
    "print(f'model training: {model3.name}')\n",
    "history_3 = model3.fit(train_dataset, validation_data=test_dataset, batch_size=256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e591200b-6a04-467e-a1ea-225252956869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Веса модели 10_Seq2Seq_attention_GRUCell сохранены\n"
     ]
    }
   ],
   "source": [
    "print('-'*30)\n",
    "model3.save_weights(f'10_{model3.name}.weights.h5')\n",
    "print(f'Веса модели 10_{model3.name} сохранены')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "408a4d60-d545-4888-8d1c-d49654b9e024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Веса модели 10_Seq2Seq_attention_GRUCell загружены\n"
     ]
    }
   ],
   "source": [
    "model3.load_weights(f'10_{model3.name}.weights.h5')\n",
    "print(f'Веса модели 10_{model3.name} загружены')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e3c8b9b5-bf00-4dcc-a439-c6a657f9eb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['Я люблю пиво', 'Я хочу в отпуск', 'Суббота лучший день для учёбы', 'Котик уснул на кровати']\n",
    "translates_texts = []\n",
    "for text in texts:\n",
    "    translates_texts.append(translate(text, tokenizer, model3, 16, type_cell='GRU', name_model='Seq2Seq_attention_GRUCell', flg_attention=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "00c3cca4-d72e-4101-b5ce-08104c568b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like beer, I love a beer.',\n",
       " 'I want to go to vacation.',\n",
       " 'The future is the best day in the world.',\n",
       " 'The cat fell asleep on the bed.']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translates_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb15bb1-3ca6-46bf-bb00-b942be60549f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8594596-9b5f-4b52-85ba-a130392d5f0e",
   "metadata": {},
   "source": [
    "# Training and Testing 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbb93b2-b4d4-4269-ba89-c6d59d25fba0",
   "metadata": {},
   "source": [
    "Использовались все состояния для подачи в декодер, а не только последнее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "638ed279-d289-4ab0-8665-db275dd5021b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate2(\n",
    "    text: str,\n",
    "    tokenizer: Tokenizer,\n",
    "    model: keras.Model,\n",
    "    max_len: int = 20,\n",
    "    type_cell: str = 'LSTM',\n",
    "    name_model: str = 'Seq2Seq',\n",
    "    flg_attention: bool = True\n",
    ") -> str:\n",
    "    '''Predicts `text`translation using the `model`.\n",
    "\n",
    "    Arguments:\n",
    "        text: text to be translated\n",
    "        tokenizer: tokenizer to use\n",
    "        model: model ot use\n",
    "        max_len: maximum length of the prediction (in tokens)\n",
    "\n",
    "    Returns:\n",
    "        tranlated text'''\n",
    "\n",
    "    encorder_emm = model.get_layer(f'{name_model}_embedding_encoder')\n",
    "    encoder_rnn = model.get_layer(f'{name_model}_bidirectional')\n",
    "\n",
    "    input_seq =  tokenizer(text, return_tensors='np', add_special_tokens=False)['input_ids'].astype(np.int32)\n",
    "    encoder_outputs, *states = encoder_rnn(encorder_emm(input_seq))\n",
    "\n",
    "    if type_cell == 'LSTM':\n",
    "\n",
    "        forwards_st = states[:len(states) // 2]\n",
    "        backwards_st = states[len(states) // 2:]\n",
    "        initial_state = [\n",
    "            [\n",
    "                tf.keras.ops.concatenate([forwards[0], backwards[0]], axis=-1),\n",
    "                tf.keras.ops.concatenate([forwards[1], backwards[1]], axis=-1)\n",
    "            ]\n",
    "            for (forwards, backwards) in zip(forwards_st, backwards_st)\n",
    "        ]\n",
    "\n",
    "    else:\n",
    "        forwards_st = states[:len(states) // 2]\n",
    "        backwards_st = states[len(states) // 2:]\n",
    "        initial_state = [tf.keras.ops.concatenate([forwards[0], backwards[0]], axis=-1) for (forwards, backwards) in zip(forwards_st, backwards_st)]\n",
    "        \n",
    "\n",
    "    target_seq = [tokenizer.pad_token_id]\n",
    "    \n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    decoder_embedding = model.get_layer(f'{name_model}_embedding_decoder')\n",
    "    decoder_rnn = model.get_layer(f'{name_model}_rnn_decoder').cell\n",
    "    decoder_dance = model.get_layer(f'{name_model}_output')\n",
    "    if flg_attention:\n",
    "        attention_layer = model.get_layer(f'{name_model}_attention')\n",
    "        \n",
    "\n",
    "    states = initial_state\n",
    "    for _ in range(max_len):\n",
    "\n",
    "        embedding = decoder_embedding(np.array(target_seq[-1]))\n",
    "        rnn, *states = decoder_rnn(embedding, states)\n",
    "        states = states[0]\n",
    "        if flg_attention:\n",
    "            attention = attention_layer([rnn, encoder_outputs])[0]\n",
    "            rnn = tf.keras.ops.concatenate([rnn, attention], axis=-1)\n",
    "        \n",
    "        output = decoder_dance(rnn)\n",
    "        output_tokens = np.argmax(output.numpy(),axis=-1)[0]\n",
    "\n",
    "        sampled_word = tokenizer.decode(output_tokens)\n",
    "        \n",
    "        if output_tokens == tokenizer.pad_token_id:\n",
    "            break\n",
    "        else:\n",
    "            decoded_sentence += sampled_word\n",
    "        \n",
    "        target_seq[0] = output_tokens\n",
    "\n",
    "    return decoded_sentence.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "bc309580-336a-4660-88fe-ed47bc2ce3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Seq2Seq\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Seq2Seq\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Seq2Seq_input_enco… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_embedding_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12,865,792</span> │ Seq2Seq_input_en… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_input_deco… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_bidirectio… │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,101,248</span> │ Seq2Seq_embeddin… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_embedding_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12,865,792</span> │ Seq2Seq_input_de… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_54      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_bidirect… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_55      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_bidirect… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_56      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_bidirect… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_57      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_bidirect… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_rnn_decoder │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,674,112</span> │ Seq2Seq_embeddin… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RNN</span>)               │                   │            │ concatenate_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ concatenate_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ concatenate_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ concatenate_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ Seq2Seq_rnn_deco… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>) │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_rnn_and_at… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_rnn_deco… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_output      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">51,513,425</span> │ Seq2Seq_rnn_and_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ <span style=\"color: #00af00; text-decoration-color: #00af00\">50257</span>)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Seq2Seq_input_enco… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_embedding_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │ \u001b[38;5;34m12,865,792\u001b[0m │ Seq2Seq_input_en… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_input_deco… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_bidirectio… │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │  \u001b[38;5;34m2,101,248\u001b[0m │ Seq2Seq_embeddin… │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_embedding_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │ \u001b[38;5;34m12,865,792\u001b[0m │ Seq2Seq_input_de… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_54      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_bidirect… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_55      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_bidirect… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_56      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_bidirect… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_57      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_bidirect… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_rnn_decoder │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m3,674,112\u001b[0m │ Seq2Seq_embeddin… │\n",
       "│ (\u001b[38;5;33mRNN\u001b[0m)               │                   │            │ concatenate_54[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ concatenate_55[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ concatenate_56[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ concatenate_57[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ Seq2Seq_rnn_deco… │\n",
       "│ (\u001b[38;5;33mAdditiveAttention\u001b[0m) │                   │            │ Seq2Seq_bidirect… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_rnn_and_at… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_rnn_deco… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m1024\u001b[0m)             │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_output      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │ \u001b[38;5;34m51,513,425\u001b[0m │ Seq2Seq_rnn_and_… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │ \u001b[38;5;34m50257\u001b[0m)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">83,020,881</span> (316.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m83,020,881\u001b[0m (316.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">83,020,881</span> (316.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m83,020,881\u001b[0m (316.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2 = get_model(256,\n",
    "                   tokenizer.vocab_size,\n",
    "                   tokenizer.vocab_size,\n",
    "                   n_stacks=2,\n",
    "                   bidirectional=True,\n",
    "                   name='Seq2Seq',\n",
    "                   cell_type=tf.keras.layers.LSTMCell,\n",
    "                   attention_flg=True\n",
    ")\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6f5ca3a5-2d7e-48fd-b73f-da192f00b728",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "254d67c5-3506-4836-8fd8-e29e356c1416",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training: Seq2Seq\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731385583.524996   54605 service.cc:145] XLA service 0x151e64b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1731385583.525092   54605 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2024-11-12 14:26:23.628046: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "W0000 00:00:1731385584.106417   54605 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "2024-11-12 14:26:24.448578: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731385586.936833   60415 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_174', 2960 bytes spill stores, 4604 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731385587.034382   60421 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_174', 40 bytes spill stores, 112 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731385587.179354   60411 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_176', 2956 bytes spill stores, 4600 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731385587.295565   60409 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_178', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731385587.430506   60412 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_176', 40 bytes spill stores, 112 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731385587.948831   60408 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_4', 212 bytes spill stores, 212 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731385588.623881   60414 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_4', 44 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731385588.688170   60407 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_4', 784 bytes spill stores, 728 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731385588.715438   60420 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_178', 1748 bytes spill stores, 2168 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731385594.528659   54605 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2004/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.5794 - loss: 2.5629"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1731385985.719901   54594 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "I0000 00:00:1731385987.591373   62222 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_175', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731385987.774933   62209 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_174', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731385988.197015   62213 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_178', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731385988.255989   62212 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_178', 92 bytes spill stores, 92 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731385988.882128   62223 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_181', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731385989.077256   62222 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_4', 216 bytes spill stores, 216 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731385989.198316   62214 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_178', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731385989.388146   62209 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_176', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731385989.389470   62215 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_174', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731385989.449337   62221 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_176', 48 bytes spill stores, 36 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731385989.584395   62211 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_174', 52 bytes spill stores, 36 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731385989.976680   62214 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_176', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731385990.173836   62213 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_176', 340 bytes spill stores, 340 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731385990.442180   62224 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_178', 348 bytes spill stores, 788 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731385990.642613   62220 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_174', 340 bytes spill stores, 340 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731385990.953153   62213 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_4', 212 bytes spill stores, 212 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.5794 - loss: 2.5626"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1731385996.704655   54594 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "W0000 00:00:1731386046.355852   54604 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 226ms/step - accuracy: 0.5794 - loss: 2.5624 - val_accuracy: 0.5875 - val_loss: 1.4011\n",
      "Epoch 2/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m494s\u001b[0m 246ms/step - accuracy: 0.5787 - loss: 1.1885 - val_accuracy: 0.5982 - val_loss: 0.8976\n",
      "Epoch 3/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m468s\u001b[0m 233ms/step - accuracy: 0.6110 - loss: 0.8011 - val_accuracy: 0.6024 - val_loss: 0.7861\n",
      "Epoch 4/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 244ms/step - accuracy: 0.5916 - loss: 0.6528 - val_accuracy: 0.5588 - val_loss: 0.7388\n",
      "Epoch 5/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m491s\u001b[0m 245ms/step - accuracy: 0.5792 - loss: 0.5602 - val_accuracy: 0.5572 - val_loss: 0.7159\n",
      "Epoch 6/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 243ms/step - accuracy: 0.5803 - loss: 0.4952 - val_accuracy: 0.5567 - val_loss: 0.7079\n",
      "Epoch 7/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m491s\u001b[0m 245ms/step - accuracy: 0.5826 - loss: 0.4461 - val_accuracy: 0.5481 - val_loss: 0.7092\n",
      "Epoch 8/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m486s\u001b[0m 243ms/step - accuracy: 0.5813 - loss: 0.4067 - val_accuracy: 0.5431 - val_loss: 0.7120\n",
      "Epoch 9/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m494s\u001b[0m 246ms/step - accuracy: 0.5864 - loss: 0.3735 - val_accuracy: 0.5335 - val_loss: 0.7148\n",
      "Epoch 10/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 243ms/step - accuracy: 0.5948 - loss: 0.3450 - val_accuracy: 0.5399 - val_loss: 0.7213\n"
     ]
    }
   ],
   "source": [
    "print(f'model training: {model2.name}')\n",
    "history_2 = model2.fit(train_dataset, validation_data=test_dataset, batch_size=256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49720884-f6bf-4252-bf33-b86b05c94382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Веса модели 13_11_LSTM_attention_Seq2Seq сохранены\n"
     ]
    }
   ],
   "source": [
    "print('-'*30)\n",
    "model2.save_weights(f'13_11_LSTM_attention_{model2.name}.weights.h5')\n",
    "print(f'Веса модели 13_11_LSTM_attention_{model2.name} сохранены')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8ebacc57-ec6c-4167-9f79-2f52b3edd3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Веса модели 13_11_LSTM_attention_Seq2Seq загружены\n"
     ]
    }
   ],
   "source": [
    "model2.load_weights(f'13_11_LSTM_attention_{model2.name}.weights.h5')\n",
    "print(f'Веса модели 13_11_LSTM_attention_{model2.name} загружены')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "be90dbd9-0270-4560-904a-0447917f6ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['Я люблю пиво', 'Я хочу в отпуск', 'Суббота лучший день для учёбы', 'Котик уснул на кровати']\n",
    "translates_texts = []\n",
    "for text in texts:\n",
    "    translates_texts.append(translate2(text, tokenizer, model2, 16, type_cell='LSTM', name_model='Seq2Seq', flg_attention=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "87329616-992a-4d75-b5ef-55959b1f36c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like beer a beer.',\n",
       " 'I want to go to a vacation.',\n",
       " 'Saturday is the best day for the study of life.',\n",
       " 'The cat fell asleep on the bed.']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translates_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f972af33-4736-40e2-aca4-35354f5a1484",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6915f5f6-300c-4041-b1a9-c8d47bfa1fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Seq2Seq_attention_GRUCell\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Seq2Seq_attention_GRUCell\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Seq2Seq_attention_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">6,432,896</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">396,288</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">6,432,896</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_64      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_65      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">691,200</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RNN</span>)               │                   │            │ concatenate_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ concatenate_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>) │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">25,781,841</span> │ Seq2Seq_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ <span style=\"color: #00af00; text-decoration-color: #00af00\">50257</span>)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Seq2Seq_attention_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m6,432,896\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m396,288\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m6,432,896\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_64      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_65      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m691,200\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mRNN\u001b[0m)               │                   │            │ concatenate_64[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ concatenate_65[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │        \u001b[38;5;34m256\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mAdditiveAttention\u001b[0m) │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ Seq2Seq_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Seq2Seq_attention_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │ \u001b[38;5;34m25,781,841\u001b[0m │ Seq2Seq_attentio… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │ \u001b[38;5;34m50257\u001b[0m)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,735,377</span> (151.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m39,735,377\u001b[0m (151.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,735,377</span> (151.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m39,735,377\u001b[0m (151.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model3 = get_model(128,\n",
    "                   tokenizer.vocab_size,\n",
    "                   tokenizer.vocab_size,\n",
    "                   n_stacks=2,\n",
    "                   bidirectional=True,\n",
    "                   name='Seq2Seq_attention_GRUCell',\n",
    "                   cell_type=tf.keras.layers.GRUCell,\n",
    "                   attention_flg=True\n",
    ")\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e9eef834-1596-4383-9169-c9b35e6075de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0cb1ca9d-8ce5-44a5-ac16-75ae4126c93f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training: Seq2Seq_attention_GRUCell\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1731391502.699465   54606 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "I0000 00:00:1731391503.863547   85680 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_239', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731391504.063365   85682 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_244', 112 bytes spill stores, 112 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731391504.208980   85691 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_239', 112 bytes spill stores, 112 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731391505.178583   85693 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_4', 784 bytes spill stores, 728 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731391505.194674   85688 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_244', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731391505.211776   85684 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_236', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731391505.406927   85686 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_4', 212 bytes spill stores, 212 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731391505.521111   85681 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_4', 44 bytes spill stores, 40 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2004/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.4778 - loss: 2.6610"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1731391706.827175   54598 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "I0000 00:00:1731391708.278776   86623 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_4', 212 bytes spill stores, 212 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731391708.340689   86615 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_4', 216 bytes spill stores, 216 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731391708.645449   86622 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_239', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731391708.729829   86626 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_4', 260 bytes spill stores, 260 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731391708.795133   86618 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_244', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731391708.889756   86614 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_236', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "I0000 00:00:1731391710.084523   86625 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_239', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.4778 - loss: 2.6608"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1731391714.414298   54598 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "W0000 00:00:1731391743.240585   54601 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 117ms/step - accuracy: 0.4777 - loss: 2.6605 - val_accuracy: 0.4193 - val_loss: 1.5458\n",
      "Epoch 2/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 121ms/step - accuracy: 0.4718 - loss: 1.3590 - val_accuracy: 0.5486 - val_loss: 1.0384\n",
      "Epoch 3/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 121ms/step - accuracy: 0.5512 - loss: 0.9376 - val_accuracy: 0.5798 - val_loss: 0.9001\n",
      "Epoch 4/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 121ms/step - accuracy: 0.5625 - loss: 0.7752 - val_accuracy: 0.5652 - val_loss: 0.8428\n",
      "Epoch 5/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 121ms/step - accuracy: 0.5636 - loss: 0.6823 - val_accuracy: 0.5664 - val_loss: 0.8150\n",
      "Epoch 6/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 121ms/step - accuracy: 0.5787 - loss: 0.6195 - val_accuracy: 0.5366 - val_loss: 0.8023\n",
      "Epoch 7/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 121ms/step - accuracy: 0.5907 - loss: 0.5737 - val_accuracy: 0.5431 - val_loss: 0.7956\n",
      "Epoch 8/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 121ms/step - accuracy: 0.6063 - loss: 0.5378 - val_accuracy: 0.5863 - val_loss: 0.7910\n",
      "Epoch 9/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 121ms/step - accuracy: 0.6161 - loss: 0.5091 - val_accuracy: 0.5694 - val_loss: 0.7933\n",
      "Epoch 10/10\n",
      "\u001b[1m2005/2005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 121ms/step - accuracy: 0.6062 - loss: 0.4851 - val_accuracy: 0.5907 - val_loss: 0.7979\n"
     ]
    }
   ],
   "source": [
    "print(f'model training: {model3.name}')\n",
    "history_3 = model3.fit(train_dataset, validation_data=test_dataset, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "40229f75-00d1-4e7d-a226-1ebbbf865d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Веса модели 13_11_Seq2Seq_attention_GRUCell сохранены\n"
     ]
    }
   ],
   "source": [
    "print('-'*30)\n",
    "model3.save_weights(f'13_11_{model3.name}.weights.h5')\n",
    "print(f'Веса модели 13_11_{model3.name} сохранены')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "9718dffe-9771-4ebd-b9a7-141fb17540d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Веса модели 13_11_Seq2Seq_attention_GRUCell загружены\n"
     ]
    }
   ],
   "source": [
    "model3.load_weights(f'13_11_{model3.name}.weights.h5')\n",
    "print(f'Веса модели 13_11_{model3.name} загружены')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "fd2d5b39-44df-4c40-9edd-9d60ee75a4a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "texts = ['Я люблю пиво', 'Я хочу в отпуск', 'Суббота лучший день для учёбы', 'Котик уснул на кровати']\n",
    "translates_texts = []\n",
    "for text in texts:\n",
    "    translates_texts.append(translate2(text, tokenizer, model3, 16, type_cell='GRU', name_model='Seq2Seq_attention_GRUCell', flg_attention=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e2c5d3a2-e258-4f8c-bd9c-0d4d28793a08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like beer.',\n",
       " 'I want to go to the supermarket.',\n",
       " 'Saturday is for the day learning.',\n",
       " 'The cat fell asleep on the bed.']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translates_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c438d9-479c-4a21-bc1d-abaff6eab75b",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
